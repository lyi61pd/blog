---
title: Mysql
date: 2025-04-10
tags:
    - Mysql
---

# Mysql基础
MySQL 是一个开源的关系型数据库管理系统，说白了就是可以用它来存储、查询和管理数据。比如写个网站，有用户、有商品、有订单，这些数据全都可以塞进 MySQL 里。

它属于 “关系型” 的那种数据库，意思就是数据是按表格来组织的（跟 Excel 差不多的感觉），表和表之间可以建立关系。

MySQL 的流行程度非常高，从小公司到大厂基本都会用，生态也非常完善。

## MySQL 和其他数据库有什么不同？
+ MySQL 是开源的，可以免费用
+ 跟 PostgreSQL 比，它性能高点但功能稍少
+ 跟 Oracle 或 SQL Server 比，它更轻量、容易上手

## 数据库的基本概念
用 MySQL 最常打交道的几个东西：

+ 数据库（Database）：相当于一个文件夹，里面放表
+ 表（Table）：一张张结构化的表格
+ 行（Row）：每条数据就像表格的一行
+ 列（Column）：表格的一列，也就是字段
+ 主键（Primary Key）：每一行的唯一标识，比如 id
+ 索引（Index）：加速查询用的，就像书的目录
+ 视图（View）：虚拟表，本质是个查询的结果
+ 存储过程、触发器等：偏后面点的高级操作，可以之后再学

## MySQL 区分大小写吗？
+ 表名是否区分大小写，跟系统有关。Linux 下区分，Windows 下不区分。
+ 字段名一般不区分。
+ 字段里的值是否区分大小写，取决于字符集和排序规则（collation）。

## 怎么创建数据库和表？
```sql
CREATE DATABASE myapp;

USE myapp;

CREATE TABLE users (
  id INT PRIMARY KEY AUTO_INCREMENT,
  name VARCHAR(100),
  age INT,
  created_at DATETIME
);
```

这段 SQL 创建了一个名为 `myapp` 的数据库，以及一张 `users` 表。字段里 `AUTO_INCREMENT` 是自增主键，常见套路。

## 数据类型该怎么选？
+ 整数：`INT`、`BIGINT`（根据范围选）
+ 字符串：`VARCHAR`（变长）、`CHAR`（定长）
+ 文本：`TEXT`，但不能做索引
+ 时间：`DATETIME`、`TIMESTAMP`
+ 布尔值：没有 `BOOLEAN`，用 `TINYINT(1)` 模拟

选类型的时候，别盲目追求“大”，越精确越节省空间和性能。

---

# 索引
简单说，索引就是数据库用来加快查找速度的一个“加速器”。就像看书有目录，你不会每次都从头翻，只要查一下页码就能直接跳过去。

在 MySQL 中，如果没有索引，数据库每次查数据都要从头到尾一条条扫，叫做 **全表扫描**，当数据多了之后，这种查询会非常慢。

## 为什么需要索引
想象你有一张表，几百万条记录，你想查 “名字叫小明的人”，没有索引的话，MySQL 会很累，要一条条看过去。加了索引之后，就可以直接跳到“名字 = 小明”的那几条记录。

所以，索引主要解决的问题就是：

+ 加快查询速度（读得快）
+ 排序、分组也能更高效
+ 可以帮助做唯一性约束（比如用户名不能重复）

## 加了索引，是不是越多越好
不是的，索引不是白送的，它有代价：

+ 会占用额外的磁盘空间
+ 写入、更新会变慢，因为要同步更新索引
+ 索引太多反而可能让查询优化器懵逼，不知道该用哪个

所以得有选择性地加，不能一上来就 “全字段都加个索引试试”。

## MySQL 的索引底层怎么实现
MySQL 默认用的是 **B+ 树索引**。这是种多路平衡查找树，跟普通的二叉树不一样，B+ 树每个节点可以有很多个子节点，并且所有数据都在“叶子节点”。

优点是：

+ 查询次数少，磁盘 IO 少
+ 顺序读取也快，适合做范围查询

另外还有一种 **哈希索引**，但它只能用于等值查找，不支持范围查找，MyISAM 不支持，InnoDB 默认也不用。

## 索引的几种类型
### 主键索引（Primary Key）
+ 表里只能有一个
+ 自动加索引
+ InnoDB 下是聚簇索引（数据和索引放一起）

### 唯一索引（Unique Index）
+ 限制某字段不能重复，比如邮箱、用户名等
+ 和主键差不多，但可以有多个

### 普通索引（Index）
+ 没有限制，只是为了加速查询

### 组合索引（联合索引）
+ 一次索引多个字段，比如 `(name, age)`
+ 遵循“最左前缀”原则，查询要从最左边字段开始才有效

### 全文索引（Fulltext）
+ 用来做全文搜索（比如查一段文字里有没有某个词）
+ MySQL 5.6 后支持 InnoDB，但功能比不上专业的全文检索引擎（比如 Elasticsearch）

## 聚簇索引和非聚簇索引区别在哪
+ 聚簇索引：数据和索引放一起（InnoDB 的主键索引），B+树的叶子节点放数据
+ 非聚簇索引：索引里存的是主键的值，查的时候需要回表，`create index` 创建的是非聚簇索引，它为表中某个或多个列提供了独立的索引结构，不改变数据的物理存储顺序

比如你查 `name`，但主键是 `id`，那先查到 `id`，然后再去表里拿其他字段，叫做 **回表**。所以非聚簇索引比聚簇的多一步操作。

## 索引应该怎么加
几个常见的加法操作：

```sql
-- 创建索引
CREATE INDEX idx_name ON users(name);

-- 创建组合索引
CREATE INDEX idx_name_age ON users(name, age);

-- 删除索引
DROP INDEX idx_name ON users;

-- 创建唯一索引
CREATE UNIQUE INDEX idx_email ON users(email);
```

## 加索引的最佳实践
+ 经常出现在 `WHERE`、`ORDER BY`、`GROUP BY`、`JOIN` 里的字段可以考虑加索引
+ 不要给频繁更新的字段加索引，会拖慢写入
+ 字段的区分度要高（重复值越少越好），不然索引效果很差
+ 索引字段顺序很重要，组合索引得用对“最左前缀”原则
+ 大字段（比如 TEXT、BLOB）不要加索引

## 为什么加了索引却没生效？
+ 查询条件没用到最左前缀
+ 用了函数包裹字段，比如 `WHERE UPPER(name) = 'TOM'`
+ 数据太少，MySQL 判断不用索引更快
+ 查询用到了模糊匹配开头，比如 `LIKE '%abc'`，这种索引就用不上

可以用 `EXPLAIN` 看看查询计划，判断是不是用了索引。



## 稀疏索引（Sparse Index）
**稀疏索引** 是一种索引类型，其中并不是对每一行数据都建立索引，而是仅对数据块或数据页中的部分行建立索引。具体来说，它在数据表中的每一页（或某些范围）选择一小部分数据作为索引项，从而减少了存储空间和维护开销。**稀疏索引 **是clickhouse使用的索引，不是MySQL。ClickHouse **不支持传统的索引**（如 B-tree 和哈希索引），但通过使用 **主键排序** 和 **稀疏索引**，ClickHouse 实现了基于列存储的数据优化。

### 特点：
+ **节省存储空间**：不像传统索引那样对每一行数据都建立索引，因此占用的存储空间较少。
+ **查询效率较低**：虽然存储空间小，但查找时需要跳过一部分无关数据，因此查询效率通常比完整索引低。
+ **常用于大数据量的表**：适用于大数据量的表，尤其在需要快速定位某些数据范围时，例如大规模的日志文件或时序数据。

### 举例：
假设你有一个大的表，而这个表有 100 万行数据。通过稀疏索引，你可能只会对每 1000 行数据建立一个索引，而不是为每一行数据建立索引。这样，查询时，索引会帮助你找到大致的位置，但仍然需要检查一些数据块中的具体内容。

---

## 倒排索引（Inverted Index）
**倒排索引** 常见于全文搜索引擎或文档检索系统。它的基本思想是：给定一个文本字段，倒排索引记录该字段中每个单词（或词条）出现的位置。倒排索引把文档或记录中的词汇与它们出现的具体位置关联起来，从而能在搜索时快速定位相关文档或记录。倒排索引是一种数据结构。

### 特点：
+ **文本搜索优化**：倒排索引特别适用于文本或字符类型字段的搜索（例如搜索引擎中的关键词搜索）。
+ **建立索引时需要分词**：每个单词、词条或者关键词都会被拆分成单独的项进行索引。
+ **支持快速全文检索**：可以快速查找一个特定单词在哪些文档中出现，并返回这些文档的 ID 或位置。

### 举例：
假设你有一组文档：

1. "the cat"
2. "the dog"
3. "cat and dog"

倒排索引会如下记录：

+ **cat** -> [1, 3]
+ **dog** -> [2, 3]
+ **the** -> [1, 2, 3]
+ **and** -> [3]

这样，当你查询 “cat” 时，倒排索引会迅速告诉你，"cat" 出现在文档 1 和文档 3 中。

---

## 全文索引（Full-Text Index）
**全文索引** 是一种针对文本数据字段的特殊索引类型，用于加速基于文本内容的查询（如关键字搜索）。它基于倒排索引原理，主要用于支持高效的文本检索。通常，全文索引会对文本内容进行分词处理，将文本拆分成单个的词条，并为每个词条建立索引。

**全文索引** 和 **倒排索引** 在概念上是相关的，但它们并不是完全一样的东西。实际上，**全文索引** 通常是基于 **倒排索引** 实现的。可以说，**倒排索引 **是实现 **全文索引 **的一种常见方式。**全文索引**通常使用**倒排索引**作为底层数据结构。**倒排索引 **提供了高效的查找能力，使得**全文索引**可以快速响应基于单词的查询。**全文索引 **不仅仅是倒排索引，它还包括了对文本的分词、停用词（如 "the"、"a" 等不重要的词）的过滤、词干提取（例如将 "running" 归一化为 "run"）以及复杂查询的支持等。这些操作使得全文索引比简单的倒排索引更加复杂。

### 特点：
+ **适用于大文本数据**：全文索引广泛用于大型文本数据的搜索，如博客、评论、文章、文档等。
+ **支持复杂的文本查询**：不仅支持精确匹配，还支持模糊查询、词频查询、近似匹配等复杂搜索方式。
+ **需要额外的存储和处理开销**：由于需要对文本进行分词处理、存储词频等信息，全文索引会比传统索引占用更多的存储空间。

### 举例：
例如，假设你对包含文章内容的数据库字段创建了全文索引，查询 `dog` 时，可以返回所有包含单词 “dog” 的文章，不仅是精确匹配，还可能包括包含类似词的结果，如 “dogs” 或 “dogged”。

---

## 覆盖索引 (Covering Index)
**覆盖索引** 是指索引包含了查询所需的所有列的数据。也就是说，在查询过程中，MySQL 可以直接从索引中获取结果，而不需要访问实际的数据表。通过使用覆盖索引，MySQL 可以避免“回表”操作（即去访问数据表），从而提高查询效率。

**什么情况下使用覆盖索引**

+ 查询的所有列（包括 `SELECT` 字段、`WHERE` 子句中的过滤条件、`ORDER BY` 子句等）都包含在索引中。
+ 这种情况下，查询会直接从索引中获取结果，避免了扫描数据表的过程。



---

## 最左前缀原则
**最左前缀原则**（**Leftmost Prefix Principle**）是关系型数据库中索引的一个重要概念，尤其是在 **复合索引**（multi-column index）中。它指的是，在使用复合索引时，查询条件必须匹配索引的**最左部分**，即从复合索引的最左侧开始的列，才能充分利用复合索引。

### 解释
在Mysql的InnoDB引擎中，默认索引用的是B+树，因为 B+ 树是一个**从根到叶子是有序搜索路径**，如果**不从最左边字段开始搜索，就无法走索引路径**。

在 MySQL 中，当创建一个复合索引（一个包含多个列的索引）时，这个索引是基于列的顺序来组织的。**最左前缀原则**要求，查询条件必须按照索引中列的顺序，至少使用索引的最左边的部分，才能有效地利用该复合索引。

### 规则
+ **最左前缀原则**意味着查询中的 `WHERE` 子句，应该从复合索引的最左边的列开始依次使用。如果某个查询条件没有匹配索引的最左边的列或部分列，MySQL 就不能完全利用这个复合索引。
+ 换句话说，复合索引的使用是按顺序的，查询条件需要依次包含索引中的列。

### 示例
假设你有以下复合索引：

```sql
CREATE INDEX idx_name ON employees (last_name, first_name, hire_date);
```

这个索引是针对 `last_name`、`first_name` 和 `hire_date` 列创建的。根据 **最左前缀原则**，这个索引可以在以下查询中有效：

1. **完全匹配最左前缀**：

```sql
SELECT * FROM employees WHERE last_name = 'Smith' AND first_name = 'John';
```

这个查询首先使用了 `last_name`，然后使用了 `first_name`，符合最左前缀原则，可以有效地使用复合索引。

2. **只匹配最左前缀的一部分**：

```sql
SELECT * FROM employees WHERE last_name = 'Smith';
```

这个查询仅使用了索引的第一个列 `last_name`，它也可以有效地使用这个复合索引。

3. **匹配最左前缀的一部分但不完全**：

```sql
SELECT * FROM employees WHERE first_name = 'John';
```

这个查询只使用了索引的第二列 `first_name`，没有使用索引的第一个列 `last_name`。根据最左前缀原则，**这个查询不能有效使用复合索引**。它可以使用其他索引（如果存在的话），但不会使用 `idx_name` 这个复合索引。

4. **跳过最左前缀的一部分**：

```sql
SELECT * FROM employees WHERE hire_date = '2022-01-01';
```

这个查询使用了索引中的第三列 `hire_date`，但它跳过了前两列 `last_name` 和 `first_name`，**所以也不能使用复合索引**。

5. **LIKE 查询**
+ `LIKE 'abc%'` 可以使用 B+ 树范围查找
+ `LIKE '%abc'` 无法使用索引（前缀不确定）
+ `LIKE 'a_b%'` 仍然能走索引
+ `WHERE name LIKE 'abc%' AND age = 30` name 是前缀，但 age 是索引最左字段，没用

### Bonus
经过测试，MYSQL的优化器会自动调整查询的过滤条件的顺序，以自动匹配最左前缀原则

```plain
create index idx_test on ds_vul(source, fixed_time)

-- 匹配
explain select * from ds_vul where fixed_time > "2020-01-01" and source ='vim' 

-- 也匹配，因为MYSQL优化器会自动调整顺序
explain select * from ds_vul where source ='vim' and fixed_time > "2020-01-01"

-- 不匹配
explain select * from ds_vul where fixed_time > '2020-01-01';
```

### 为什么最左前缀原则如此重要
+ **复合索引的性能优化**：复合索引是为了加速包含多个列的查询，但它的顺序非常重要。如果查询条件没有按照索引列的顺序提供，数据库引擎将无法有效使用该索引。
+ **查询效率**：如果查询的列顺序与复合索引的顺序不匹配，数据库必须回退到全表扫描或其他不太高效的查询方式，从而影响查询效率。

### 如何优化
1. **合理设计索引顺序**：根据查询模式来设计索引的列顺序。将最常用的查询列放在复合索引的最左边，以确保查询时能够充分利用索引。
2. **避免不必要的列**：如果某些列在查询中使用的频率较低，可以考虑不将它们放在复合索引的最左侧，或者通过单独的索引来优化。
3. **覆盖索引**：如果查询仅涉及复合索引中的列，可以利用覆盖索引（covering index），避免回表查询，从而提高查询效率。

# **SQL 查询优化和执行计划分析**
## SQL 查询的执行顺序
你写的是这样：

```sql
SELECT name FROM users WHERE age > 18 ORDER BY created_at;
```

但 MySQL 实际上是按照这个顺序执行的：

1. `FROM`（先确定要从哪张表查）
2. `WHERE`（先过滤数据）
3. `GROUP BY`（如果有分组先分组）
4. `HAVING`（对分组后的数据再过滤）
5. `SELECT`（确定要查哪些字段）
6. `ORDER BY`（最后排序）
7. `LIMIT`（控制输出条数）

---

## 怎么用 EXPLAIN 看执行计划
`EXPLAIN` 是调试 SQL 性能的关键工具。可以这么用：

```sql
EXPLAIN SELECT name FROM users WHERE age > 18;
```

它会输出一堆字段，几个核心的要会看：

+ `type`：连接类型，越靠近 `const` 越好（顺序大概是：ALL > index > range > ref > eq_ref > const）
+ `possible_keys`：MySQL 觉得哪些索引可以用
+ `key`：实际用了哪个索引
+ `rows`：大概扫描了多少行
+ `Extra`：有没有 “Using filesort”、“Using temporary” 这类提示，说明有潜在问题

### 常见提示的含义
+ `ALL`：全表扫描，通常不是好事
+ `Using filesort`：用到了额外排序操作，效率较低
+ `Using temporary`：中间生成了临时表，占内存或磁盘，注意优化

---

## 怎么找出慢查询
可以开启 MySQL 的 **慢查询日志**，用来记录那些执行时间超过某个阈值的 SQL。

设置方式（示例）：

```sql
-- 开启慢查询日志
SET GLOBAL slow_query_log = 1;

-- 设置记录阈值，比如超过 1 秒的记录
SET GLOBAL long_query_time = 1;

-- 设置记录日志的文件路径（一般默认就有）
SHOW VARIABLES LIKE 'slow_query_log_file';
```

然后可以分析这些日志，看看哪些 SQL 是“拖后腿的家伙”。

---

## 常用 SQL 优化技巧
### 1. SELECT 需要啥就写啥，别用 `SELECT *`
+ `SELECT *` 会返回所有字段，拖慢速度
+ 表结构一改，程序可能挂
+ 更难走索引覆盖

### 2. 建合适的索引
+ 经常查的字段加索引，比如 `WHERE`、`JOIN`、`ORDER BY` 里出现的
+ 组合索引按使用顺序排，记住“最左前缀”
+ 不要滥用索引，写操作多的表慎重

### 3. 使用 `LIMIT` + 索引分页
大分页特别慢，比如：

```sql
SELECT * FROM big_table LIMIT 100000, 20;
```

可以用 **延迟分页** 优化：

```sql
SELECT * FROM big_table WHERE id > 上次最后一条的id LIMIT 20;
```

这样可以用上索引，避免跳过大量无用数据。

### 4. 注意函数和隐式转换
这些都可能让索引失效：

```sql
WHERE DATE(created_at) = '2024-01-01'  -- 会失效
WHERE created_at >= '2024-01-01' AND created_at < '2024-01-02'  -- 推荐这样写
```

类型不一致也会让索引失效：

```sql
WHERE id = '123'  -- 如果 id 是 INT 类型，这样写可能导致类型转换
```

---

## 常见问题整理
### 为什么明明有索引，SQL 还是很慢
+ 索引字段用错了位置，比如用了函数
+ 查询字段太多，回表成本高
+ 数据量太少，MySQL 判断全表扫描更快
+ 没走覆盖索引（select 的字段不在索引里）

### 怎么判断是否走了“覆盖索引”
`EXPLAIN` 里 `Extra` 出现 `Using index`，说明是走了覆盖索引（不需要回表）

### 什么是 filesort，为什么要避免
MySQL 发现没法用索引排序，就会启用 filesort，可能会写磁盘，效率低。避免它的方法：

+ 对排序字段加索引
+ 避免 `ORDER BY` 排多个不相关字段
+ 限制返回结果行数（比如加 `LIMIT`）

# EXPLAIN
`EXPLAIN` 是 MySQL 用来查看 SQL 执行计划的命令，可以帮助分析 SQL 是否使用了索引，是否存在性能问题。通过它可以提前预判一条 SQL 的执行路径，而不是靠“感觉”去优化。

适用于 `SELECT`、`DELETE`、`INSERT`、`REPLACE`、`UPDATE` 等语句（但最常用于 `SELECT`）。

---

## 如何使用 EXPLAIN？
用法非常简单，只需要在查询语句前面加上 `EXPLAIN` 即可：

```sql
EXPLAIN SELECT name FROM users WHERE age > 25;
```

MySQL 会返回一个表格，包含若干列，每列都对应一个执行计划的关键字段。理解这些字段，是掌握 SQL 调优的关键。

---

## EXPLAIN 的输出字段详解
### id
表示查询中每个 SELECT 子句或操作的编号，数字越大表示优先级越高。简单查询通常只有一行，复杂查询（如子查询、联合查询）会出现多行。

+ `id` 相同：表示是一个查询块
+ `id` 不同：先执行 id 值大的

### select_type
表示查询的类型，常见的有：

+ `SIMPLE`：简单查询，不包含子查询或 UNION
+ `PRIMARY`：最外层的查询
+ `SUBQUERY`：在 `SELECT` 或 `WHERE` 中出现的子查询
+ `DERIVED`：出现在 `FROM` 子句中的子查询（派生表）
+ `UNION`：UNION 中的第二个或后续查询
+ `DEPENDENT SUBQUERY`：依赖外层查询结果的子查询

### table
表示当前这一步操作涉及到的表名，可能是具体表名、临时表，或者 `derivedN`（派生表）。

### type
以下是 `EXPLAIN` 中 `type` 字段的所有取值及其含义，从最差到最好，按性能排序：

| type | 含义描述 | 是否使用索引 | 性能等级 | 常见场景示例 |
| --- | --- | --- | --- | --- |
| ALL | 全表扫描，逐行检查数据 | 否 | 最差 | 没有索引或查询条件无法使用索引 |
| index | 全索引扫描，扫描整个索引 | 是 | 较差 | 覆盖索引但没有过滤条件，如只查询索引字段 |
| range | 范围扫描，使用索引的范围条件 | 是 | 较好 | `<`, `>`, `BETWEE`, `LIKE 'abc%'` 等范围查询 |
| index_merge | 使用多个单列索引并合并结果 | 是 | 一般 | 多个字段各自有索引，如 `col1 = 1 OR col2 = 2` |
| ref_or_null | 类似 ref，但同时处理 `IS NULL` 情况 | 是 | 一般 | `col = ? OR col IS NULL` |
| ref | 非唯一索引等值匹配 | 是 | 好 | `col = ?`，其中 col 是普通索引字段 |
| eq_ref | 唯一索引等值匹配，一次返回一条记录 | 是 | 很好 | 多表 JOIN 时，通过主键或唯一索引进行连接 |
| const | 主键或唯一索引等值查询，最多返回一条 | 是 | 最优 | `WHERE id = 1`，id 是主键或唯一索引 |
| system | 表只有一行（系统表） | 是 | 最优 | 极少见，仅用于单行系统表 |


说明：

+ `ALL` 和 `index` 会全扫描，性能差；
+ `range`、`ref` 是常见且推荐使用的索引访问方式；
+ `eq_ref` 和 `const` 是最优形式，查询效率极高；
+ `const` / `system`：一次匹配一行（几乎不耗资源）

推荐至少使用 `range` 级别，理想状态是 `ref` 或 `eq_ref`。

### possible_keys
表示 MySQL 认为可能使用的索引列表，基于查询条件来判断。

### key
表示实际使用的索引，如果为 `NULL`，说明没有用到任何索引。

### key_len
表示使用的索引长度（单位是字节），可以用来判断索引是否被“用全”。

比如索引是 `(name, age)`，但 SQL 只用了 `name`，那 `key_len` 就只体现了 `name` 的长度。

### ref
表示使用哪个字段或常量与索引进行比较。常见值：

+ `const`：与常量比较
+ `func`：使用函数
+ `NULL`：没用上

### rows
MySQL 预估本次执行需要扫描的行数。这个值越小越好，是判断是否走索引的直接指标。

需要注意的是，它只是预估值，不一定完全准确。

### filtered
表示在读取到 `rows` 行数据后，经过 `WHERE` 条件过滤后剩下的比例。比如 100 行中 10 行满足条件，那就是 `10.0`。

这个字段可以结合 `rows` 看最终参与返回的行数。

### Extra
这是执行计划中最值得关注的一列，包含一些额外信息，常见的有：

+ `Using index`：用了覆盖索引（非常好）
+ `Using where`：用了 `WHERE` 条件过滤
+ `Using filesort`：需要额外排序操作（可能影响性能）
+ `Using temporary`：使用了临时表（比如 `GROUP BY`、`ORDER BY`）
+ `Impossible WHERE`：永远不可能成立的条件，比如 `WHERE 1=0`

---

## 判断是否使用了索引
优先关注这几列的值：

+ `type`：如果是 `ALL` 或 `index`，说明没走有效索引
+ `key`：是否非 NULL，代表是否实际用上索引
+ `Extra`：是否出现 `Using filesort` 或 `Using temporary`

一个比较理想的结果是：

+ `type = ref` 或更优
+ `key` 有值
+ `rows` 很少
+ `Extra` 里有 `Using index` 而没有 `Using filesort` 和 `Using temporary`

---

# filesort
**filesort** 是 MySQL 用来处理 **排序操作** 的一种机制。当查询需要对结果进行排序时（如 `ORDER BY` 子句），MySQL 会使用 `filesort` 来完成排序操作。这个名字有点误导，因为它并不总是涉及文件系统排序，实际上它通常是在内存中进行的排序。

## 何时发生 filesort
`filesort` 发生在以下情况下：

+ 查询涉及 `**ORDER BY**` 子句。
+ 在某些情况下，MySQL 无法利用现有的索引来直接进行排序，于是它会将结果临时存储在内存或磁盘中进行排序。

`filesort` 的性能问题通常是因为排序的数据量较大，无法完全放入内存，导致 MySQL 需要将部分数据写入临时磁盘文件。

## 举例
假设有一个 `users` 表，查询需要按 `age` 列排序：

```sql
EXPLAIN SELECT * FROM users ORDER BY age;
```

如果 `**age**` 列没有索引，或者现有索引不能直接支持排序（比如不包含全部需要的排序列），MySQL 就会使用 `filesort` 来进行排序。`EXPLAIN` 输出中会显示 `Extra` 列为 `Using filesort`，表示查询使用了 `filesort`。

## filesort 的工作原理
+ **内存排序**：如果排序的数据集较小，并且 MySQL 配置允许使用足够的内存（通过 `sort_buffer_size` 配置项），那么 MySQL 会在内存中完成排序。
+ **磁盘排序**：如果排序的数据集太大，无法完全放入内存，MySQL 会将数据写入临时磁盘文件，然后进行排序。这个过程通常比内存排序慢得多。

---

# 事务和锁
## 什么是事务
事务（Transaction）是一组操作的集合，要么全部执行成功，要么全部失败回滚。它的目标是保证数据的正确性和一致性。

MySQL 默认的 InnoDB 引擎是支持事务的。

事务的四大特性也经常被提起：

+ 原子性（Atomicity）：事务要么全部执行，要么全部不执行
+ 一致性（Consistency）：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设[约束](https://zh.wikipedia.org/wiki/%E6%95%B0%E6%8D%AE%E5%AE%8C%E6%95%B4%E6%80%A7)、[触发器](https://zh.wikipedia.org/wiki/%E8%A7%A6%E5%8F%91%E5%99%A8_(%E6%95%B0%E6%8D%AE%E5%BA%93))、[级联回滚](https://zh.wikipedia.org/wiki/%E7%BA%A7%E8%81%94%E5%9B%9E%E6%BB%9A)等
+ 隔离性（Isolation）：事务之间互不干扰
+ 持久性（Durability）：事务提交后修改会永久保存

## 如何使用事务
可以在 SQL 中手动控制事务：

```sql
START TRANSACTION;

UPDATE accounts SET balance = balance - 100 WHERE id = 1;
UPDATE accounts SET balance = balance + 100 WHERE id = 2;

COMMIT;  -- 提交
-- 或者
ROLLBACK;  -- 回滚
```

默认情况下，MySQL 是自动提交的。每条语句执行完就自动提交。如果想关闭：

```sql
SET autocommit = 0;
```

执行完再手动提交。

## 事务提交失败时会回滚到哪里
事务中只要没提交（commit），就不会对实际数据生效。发生异常时可以通过 `ROLLBACK` 撤销未提交的改动。

## 隔离级别
**隔离级别的四种类型：**

1. **读未提交（Read Uncommitted）**
2. **读已提交（Read Committed）**
3. **可重复读（Repeatable Read），默认**
4. **串行化（Serializable）**

****

**读未提交（Read Uncommitted）**

+ **定义**：事务可以读取另一个未提交事务的数据。换句话说，一个事务可以读取到其他事务正在修改的数据（**脏读**）。
+ **问题**：
    - **脏读（Dirty Read）**：一个事务读取到另一个事务尚未提交的数据。假如另一个事务回滚了，这个读取到的数据就不再有效，导致不一致性。
+ **使用场景**：通常很少使用，因为它可能会导致数据不一致，但在某些极其宽松的一致性要求下，可能会用到。
+ **示例**： 事务 A 修改数据，但尚未提交，事务 B 读取了该数据，随后事务 A 回滚。事务 B 读取的数据是无效的。



**读已提交（Read Committed）**

+ **定义**：一个事务只能读取已经提交的事务的数据。即，事务 A 不会读取事务 B 修改但尚未提交的数据。
+ **问题**：
    - **不可重复读（Non-repeatable Read）**：事务 A 在同一事务中多次读取相同的记录，事务 B 可能在事务 A 读取两次之间修改了这条记录，导致事务 A 得到不同的值。
+ **使用场景**：适用于大多数普通的数据库应用场景，确保了数据不会出现脏读。
+ **示例**： 事务 A 读取某行数据，事务 B 修改了这行数据并提交，事务 A 再次读取同一行数据，发现内容已改变。

****

**可重复读（Repeatable Read）**

+ **定义**：在同一个事务中，多次读取相同的数据结果是相同的。事务 A 在执行期间，事务 B 不能修改事务 A 已读取的数据。MySQL 默认的隔离级别是可重复读。
+ **问题**：
    - **幻读（Phantom Read）**：事务 A 读取某个范围内的记录，事务 B 插入了新的记录，事务 A 重新读取该范围时，发现结果集发生了变化。在 MySQL 中，`**Repeatable Read**` 隔离级别默认会使用 **“间隙锁（Gap Lock）”** 来防止幻读。它会锁住数据行和数据行之间的间隙，防止其他事务在该间隙插入新记录，从而避免幻读的发生。
+ **使用场景**：适用于大多数场景，尤其是在需要保证数据一致性的情况下，例如银行转账操作。
+ **示例**： 事务 A 读取账户余额，事务 B 插入了新的账户，事务 A 再次读取账户余额时，发现余额发生变化。

****

**串行化（Serializable）**

+ **定义**：最严格的隔离级别，所有事务按顺序执行，避免了脏读、不可重复读和幻读。事务 A 执行时，其他事务无法访问正在处理的数据。
+ **问题**：
    - **性能下降**：由于所有事务都需要按顺序执行，数据库的并发性大大降低，吞吐量和响应速度会受到影响。
+ **使用场景**：适用于对数据一致性要求极高的场景，通常用于一些非常关键的操作。
+ **示例**： 事务 A 和事务 B 都试图同时修改相同的数据行，数据库会强制事务 A 等待事务 B 完成。



设置隔离级别：

```sql
SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;
```

查看当前隔离级别：

```sql
SELECT @@tx_isolation;
```

---

## MySQL 锁机制概览
InnoDB 提供了多种类型的锁机制，用来控制并发：

### 表锁 vs 行锁
+ **表锁**：一锁整个表，简单粗暴，MyISAM 用的是这个
+ **行锁**：只锁相关记录，InnoDB 支持，粒度更细，效率高

### 意向锁（意向共享锁IS / 意向排他锁IX）
用来表示某行上是否已有锁，是表锁和行锁之间的桥梁，性能更高。

**意向锁的两种类型**

+ **意向共享锁（IS, Intention Shared）**：表示“打算对某些行加共享锁”
+ **意向排他锁（IX, Intention Exclusive）**：表示“打算对某些行加排他锁”

举个例子：

`SELECT * FROM users WHERE id = 1 LOCK IN SHARE MODE;`

这条语句对 id = 1 加了共享锁（S锁），同时 InnoDB 会在整张 users 表上加一个 意向共享锁（IS）。

同理：

`SELECT * FROM users WHERE id = 1 FOR UPDATE;`

这会对该行加排他锁，同时在表上加一个 意向排他锁（IX）。

如果别的事务现在想对整张 `users` 表加排他锁，InnoDB 可以直接看：

+ 表上是否已经有 IS 或 IX 锁？
+ 如果有，就知道不能加排他锁，直接冲突

不用再去一行一行查了。

所以意向锁是一个“告诉别人我这里有锁”的机制，提高并发时加锁效率。

### 共享锁（S 锁）
允许多个事务同时读取数据，但不能写。

```sql
SELECT * FROM users WHERE id = 1 LOCK IN SHARE MODE;
```

### 排他锁（X 锁）
不允许其他事务读或写。

```sql
SELECT * FROM users WHERE id = 1 FOR UPDATE;
```

在事务中使用 `FOR UPDATE` 可以防止其他事务修改数据，常用于悲观锁场景。

### 间隙锁
**间隙锁**（**Gap Lock**）是 MySQL 中的一种锁类型，它用于锁定某个范围内的数据行之间的空隙，以防止其他事务在该范围内插入新的数据行。间隙锁通常用于防止 **幻读**（Phantom Read）问题，特别是在 `**Repeatable Read**` 隔离级别下。

**间隙锁的作用：**

+ **防止幻读**：通过锁定数据行之间的间隙，阻止其他事务在该间隙中插入新的数据行。这样可以确保在同一个事务中多次查询时，查询结果不发生变化，从而避免幻读现象。
+ **锁定范围**：与普通的行级锁不同，间隙锁不会锁定具体的数据行，而是锁定两个数据行之间的空隙，防止其他事务插入数据到这个空隙中。

## 行锁的实现方式
InnoDB 采用的是**索引上的锁**，不是直接锁整行。如果没用索引，行锁就退化成表锁。

因此，使用 `WHERE` 条件时如果没有走索引，锁粒度会变粗，影响性能。

---

## 常见问题与误区
### 行锁一定能锁住某一行吗
不一定。如果条件没用索引，InnoDB 会锁整个表范围。

### 为什么加了 FOR UPDATE 还是被其他事务修改了
可能是因为用了非事务引擎，比如 MyISAM，或者语句没有在事务中执行。

# 死锁
## 定义
**死锁** 是指多个事务在执行过程中，由于资源争用导致事务互相等待对方释放资源，进而形成一种永久等待的状态。这会导致数据库无法继续执行这些事务，造成系统性能下降或停滞。

死锁的发生通常是因为多个事务对数据库的资源（如行、表）进行并发访问，并且它们之间存在循环等待的关系。

## 死锁的四个必要条件
死锁发生的四个必要条件是：

1. **互斥条件（Mutual Exclusion）**：至少有一个资源是被一个事务独占的，其他事务不能访问该资源，直到当前事务释放资源。
2. **占有并等待条件（Hold and Wait）**：一个事务持有至少一个资源，并等待获得其他事务持有的资源。
3. **不剥夺条件（No Preemption）**：事务持有的资源不能被强制剥夺，必须等事务完成并释放资源后，其他事务才能获取这些资源。
4. **循环等待条件（Circular Wait）**：多个事务形成一个环状依赖链，每个事务都在等待下一个事务释放它所需要的资源。

当这四个条件同时满足时，就会发生死锁。

## 死锁的例子
假设有两个事务 A 和 B，它们分别执行以下操作：

+ **事务 A**：获取资源 R1，等待资源 R2。
+ **事务 B**：获取资源 R2，等待资源 R1。

此时：

+ 事务 A 持有 R1，并等待获取 R2。
+ 事务 B 持有 R2，并等待获取 R1。

由于事务 A 和事务 B 互相等待对方释放资源，它们进入了一个死锁状态，无法继续执行。

## 死锁检测和解决
### 死锁检测
大多数数据库管理系统（DBMS）可以自动检测死锁。在检测到死锁时，数据库系统会选择回滚其中一个事务以解除死锁。

+ **死锁检测算法**：数据库系统通常会构建一个**等待图**，如果图中出现环形依赖，说明发生了死锁。

### 死锁解决
当死锁发生时，数据库需要解决死锁问题，通常的做法是回滚其中一个事务。

+ **回滚事务**：数据库系统会回滚其中一个事务，释放它所占用的资源，从而打破死锁，允许其他事务继续执行。
+ **超时机制**：在一些系统中，事务如果等待锁的时间过长，可以自动回滚，以避免死锁的发生。

### 死锁预防
通过设计良好的数据库操作流程，可以尽量避免死锁的发生。例如：

+ **按固定顺序获取锁**：确保所有事务按相同的顺序请求资源，避免形成环状依赖。
+ **减少锁的粒度**：锁定尽可能小的数据范围，减少死锁的可能性。
+ **避免长时间持有锁**：事务持有锁的时间越长，死锁的机会就越大。

## 总结
+ **死锁** 是多事务并发执行时，由于互相等待而无法继续执行的状态。
+ 死锁的发生需要满足四个条件：互斥、占有并等待、不剥夺、循环等待。
+ 解决死锁的方式通常是回滚其中一个事务，释放资源，打破死锁。
+ **预防死锁** 可以通过合理设计事务的锁获取顺序、减少锁的粒度、避免长时间持有锁等方法来实现。



# 乐观锁和悲观锁
乐观锁和悲观锁不是 MySQL 内置的“锁类型”，它们是一种**并发控制策略**，而不是数据库层直接定义的“锁”。

可以理解为：**乐观锁和悲观锁，是怎么用这些数据库锁的“思路”或“方式”。**

---

## 悲观锁
悲观锁假设“别人随时可能来改数据”，所以自己在读或写之前，先把数据锁住，防止别人动。

### 在 MySQL 里怎么实现悲观锁？
InnoDB 的 `SELECT ... FOR UPDATE` 或 `LOCK IN SHARE MODE` 就是典型的悲观锁实现方式。比如：

```sql
START TRANSACTION;
SELECT stock FROM products WHERE id = 1 FOR UPDATE;
UPDATE products SET stock = stock - 1 WHERE id = 1;
COMMIT;
```

在这个过程中，如果其他事务也想对 id=1 进行 `FOR UPDATE`，就会被阻塞，直到当前事务提交或回滚。也就是说，**真的会加锁，真的会阻塞别人。**

这就是 “悲观锁”：怕别人来抢，先锁再说。

---

## 乐观锁
乐观锁的思路是：我先不锁，我假设别人不会来改，如果真有人改了，那我再处理冲突。

### 在 MySQL 里怎么实现乐观锁？
最常见的方法就是用 **版本号（version 字段）** 或 **时间戳（last_updated）** 控制。

例子：

1. 读出一条数据：当前 version 是 3
2. 处理业务逻辑
3. 更新时带上版本号：

```sql
UPDATE products 
SET stock = stock - 1, version = version + 1 
WHERE id = 1 AND version = 3;
```

如果返回行数是 1，说明没人改成功了；如果是 0，说明有人改了 version，现在不是 3 了，那这次就失败，需要重试。

这就是乐观锁：**不阻塞，但靠检测是否被改过来避免冲突。**

---

## 那跟 InnoDB 的行锁、表锁、意向锁有什么关系？
可以这样归纳：

| 名称 | 属于数据库机制 | 是否真的加锁 | 是否阻塞 | 常见语法 |
| --- | --- | --- | --- | --- |
| 行锁 | ✅ 是 | ✅ 是 | ✅ 是 | FOR UPDATE 等 |
| 表锁 | ✅ 是 | ✅ 是 | ✅ 是 | LOCK TABLE |
| 意向锁 | ✅ 是 | ✅ 是 | ✅ 是 | 自动管理，不手动写 |
| **悲观锁** | ❌ 是策略 | ✅ 借助锁 | ✅ 是 | FOR UPDATE |
| **乐观锁** | ❌ 是策略 | ❌ 不加锁 | ❌ 不阻塞 | WHERE version=x |


所以：

+ 行锁、表锁这些是底层原生机制
+ 乐观锁、悲观锁是业务设计思路，靠具体写法实现

---

## 哪种更适合大并发
+ 乐观锁：适合 **读多写少** 的业务，比如用户资料修改、库存秒杀（配合重试机制）
+ 悲观锁：适合 **写冲突多、修改必须原子性强** 的业务，比如银行转账

---

# 表设计规范和性能调优技巧
## 字段类型的选择
字段类型选得好，数据存得快、查得快，还省空间。常见建议如下：

+ 能用 `TINYINT`、`SMALLINT` 就别直接用 `INT`、`BIGINT`
+ 字段长度不要随便给个超大值，比如 `VARCHAR(255)` 不等于安全
+ 精确度要求不高的金额，用整数存，比如“以分为单位”
+ 时间字段优先使用 `DATETIME`，避免 `TIMESTAMP` 的时区问题
+ 不用 `ENUM`，扩展性差，换成 `TINYINT` + 映射表可维护性更好

## TEXT 和 VARCHAR 有啥区别
+ `VARCHAR` 是变长字符串，最多 65535 字节（和行大小有关）
+ `TEXT` 是独立存储的，不适合频繁查询或排序
+ `TEXT` 字段不能加普通索引（要用前缀索引或全文索引）

建议普通文本就用 `VARCHAR`，超过几千字符才考虑 `TEXT`

---

## 范式
范式的目标是**去重、避免冗余**。常用的是三范式：

1. 第一范式（1NF）：字段不可再分
2. 第二范式（2NF）：每列完全依赖主键（不依赖部分）
3. 第三范式（3NF）：不依赖于其他非主属性

简单说，设计上尽量拆表，避免“一个表塞所有东西”的情况。

---

## 范式为什么在项目里经常不管用
范式理论虽然漂亮，但在真实项目中，有时候为了**查询效率**，会选择**反范式设计**：

+ 把本来该拆成两张表的数据合成一张（避免 JOIN）
+ 保留一些重复字段，换取查询速度

比如电商订单表，可能会冗余存一下用户昵称、商品快照信息，就是典型的反范式实践。

---

## 拆表怎么搞，什么时候该拆
表数据一多，几百万几千万的时候，一些常规操作就开始卡顿，这时候就该考虑拆表。

### 垂直拆表
按功能或字段类别拆，比如：

+ 经常查询的字段放一张表（热点字段）
+ 不常用的大字段（比如用户简介、头像）单独放表

### 水平拆表
按数据量来拆，比如：

+ 用户表超过千万记录，可以按用户 ID 哈希分成 128 张表
+ 或者按时间分表：`orders_2024_q1`、`orders_2024_q2` 这种

可以用中间层封装拆分逻辑，比如引入 MyCAT、ShardingSphere 等分库分表中间件。

---

## 大表优化技巧
### 限制宽表设计
+ 字段太多会影响查询效率、缓存命中率
+ 大字段放外表，非热字段也可以拆

### 控制单表数据量
+ 理论上 InnoDB 支持 64TB，但实际磁盘、索引、查询压力都跟不上
+ 单表 500 万 ~ 1000 万记录开始出现性能问题是很常见的事

### 读写分离
+ 通过主从同步架构，将读操作分发到从库
+ 减少主库压力，提高并发能力

### 合理分区表（不是分表）
MySQL 还支持 **分区表**，但限制多、运维复杂，适合特定场景（如按月分区查询）。

---

## 常见问题整理
### 一张表字段太多或数据太多，哪个更危险？
都危险。字段太多会变成宽表，影响缓存、索引命中；数据太多会导致查询变慢、写入卡顿。两者都要控制在合理范围。

### VARCHAR 要不要给得很长，比如 VARCHAR(1000)
如果实际数据都很短，字段越长越浪费内存，尤其是用内存临时表的时候。建议根据实际情况定长。

### 为什么有时候拆表反而让查询更慢了
拆表会带来更多 JOIN、代码复杂度变高，如果不是瓶颈，盲目拆表是优化过度。一定要基于数据量、业务特征来判断。

---

# 存储引擎和日志
MySQL 支持多种存储引擎，理解成“不同的底层实现方式”，每种引擎对数据的读写方式、锁机制、事务支持等都不一样。

查看当前默认存储引擎：

```sql
SHOW VARIABLES LIKE 'default_storage_engine';
```

查看某张表用的存储引擎：

```sql
SHOW TABLE STATUS LIKE '表名';
```

---

## InnoDB 和 MyISAM 的主要区别
| 特性 | InnoDB | MyISAM |
| --- | --- | --- |
| 事务 | 支持 | 不支持 |
| 行级锁 | 支持 | 不支持（表锁） |
| 外键 | 支持 | 不支持 |
| 崩溃恢复能力 | 强（有日志） | 弱（容易损坏） |
| 查询性能 | 高并发时表现更好 | 适合只读或低并发 |
| 主键方式 | 聚簇索引 | 普通索引 |
| 数据存储 | 数据和索引合存 | 分开存储 |


结论是：**99% 的场景推荐用 InnoDB**，MyISAM 基本上已是历史遗产。

---

## 聚簇索引的概念
InnoDB 使用 **聚簇索引**（Clustered Index），主键索引就是数据本身，其他辅助索引存的是主键。

优点：

+ 主键查询特别快
+ 范围查询效率也高

缺点：

+ 主键太长会导致其他索引体积变大
+ 更新主键代价高（要移动整行数据）

因此，设计表时建议使用整型自增主键作为主键，简洁又高效。

---

## 日志系统
InnoDB 之所以强悍，很大程度上依赖它的日志机制：

### 重做日志（Redo Log）
+ 用来实现 **崩溃恢复**
+ 即使 MySQL 宕机，只要事务提交了，数据就能恢复

### 回滚日志（Undo Log）
+ 实现 **事务回滚** 和 **MVCC**
+ 查询操作可以看到历史版本，支撑事务的隔离性

### 二进制日志（Binlog）
+ 属于 MySQL 层日志，不依赖存储引擎
+ 用于主从同步和数据恢复

这套日志组合，让 InnoDB 实现了 **先写日志再改数据** 的写流程，保证了事务的安全性。

---

## InnoDB 的参数调优建议（初级）
### 调整 Buffer Pool
Buffer Pool 是 InnoDB 用来缓存数据和索引的内存区域，尽量给大一些，提升读写效率。

```sql
SHOW VARIABLES LIKE 'innodb_buffer_pool_size';
```

建议设为服务器内存的 60%-70%（如果是专用 MySQL 服务器）。

### 调整事务提交模式
```sql
innodb_flush_log_at_trx_commit = 1
```

这是默认设置，事务每次提交都要落盘，最安全但写入慢。

可选：

+ `0`：每秒写一次日志，不保证完全不丢数据
+ `2`：写日志但不立刻刷盘，性能高一些，有小概率丢事务

根据数据安全级别需求调整。

---

## 常见问题与解释
### 为什么主键不能随便用 UUID？
+ UUID 比 INT 长得多，插入时不连续，会导致页分裂，写入效率低
+ 占用索引空间大，影响性能
+ 更推荐使用自增 ID 或雪花 ID 这类连续主键

### 为什么不推荐用 MyISAM？
+ 没有事务，数据一多就容易出错
+ 写入时锁整张表，根本不适合高并发
+ 崩溃后可能数据恢复不了

除非是一些只读的临时表，基本没必要用 MyISAM。

### InnoDB 表一定需要主键吗？
InnoDB 表必须有主键。没有显式主键时，它会自动生成一个隐藏的 6 字节主键。但不能主动控制，所以建议明确设置主键。

# 日志系统
这一部分专注讲解 **MySQL（尤其是 InnoDB）中的日志系统**，这是事务机制、高可用能力、崩溃恢复背后的核心支撑。日志是理解数据库“为什么不会轻易丢数据”的关键。

---

## MySQL 有哪些类型的日志
常见的日志类型有这几种，各有分工：

+ **Redo Log**（重做日志） — InnoDB 独有
+ **Undo Log**（回滚日志） — InnoDB 独有
+ **Binlog**（二进制日志） — MySQL 层日志，跟存储引擎无关
+ **Error Log**（错误日志） — 系统运行中产生的错误或启动信息
+ **Slow Query Log**（慢查询日志） — 查 SQL 是否“拖后腿”
+ **General Log**（通用日志） — 记录所有 SQL，默认关闭

其中最核心、最容易混淆的，是 Redo Log、Undo Log 和 Binlog。

---

## Redo Log：保证数据持久化的关键
作用：**崩溃恢复**

InnoDB 的写流程不是直接写磁盘，而是先写 Redo Log，再异步刷数据页到磁盘。这就叫 **WAL（Write-Ahead Logging）机制**。

流程如下：

1. 修改数据页，写入内存（Buffer Pool）
2. 同时写一份日志到 Redo Log（先写磁盘）
3. 事务提交
4. 后台再慢慢把数据刷回磁盘页（称为刷新脏页）

即使数据库宕机，只要 Redo Log 写成功，重启后可以重做操作，数据不丢。



**Redo Log 有两个关键点：**

+ **逻辑结构**：是按页（Page）为单位的物理日志
+ **落盘控制**：由 `innodb_flush_log_at_trx_commit` 控制

设置值解释：

+ `1`：每次事务提交都写入磁盘（最安全，默认）
+ `2`：写到操作系统缓存，不立即刷盘（性能略高）
+ `0`：每秒写一次，崩溃时可能丢事务（性能最高）

---

## Undo Log：实现事务回滚和 MVCC 的基础
作用：

+ 回滚事务用的“反操作日志”
+ 实现多版本并发控制（MVCC）

Undo Log 记录每一次数据修改前的“旧值”，如果事务执行失败或显式回滚，就可以用 Undo Log 把数据恢复回来。

另外，读取操作也依赖 Undo Log，才能实现“事务看到的是自己那一刻的数据快照”。

---

## Binlog：主从同步的关键机制
作用：

+ 支撑主从复制
+ 做数据恢复时能用
+ 不依赖存储引擎（MyISAM、InnoDB 都会写）

Binlog 记录的是**逻辑操作**，比如“插入了这条数据”，不关心页或物理地址。

常见格式：

+ **STATEMENT**：记录原始 SQL，可能出现副作用（比如 `NOW()` 每次值都不一样）
+ **ROW**：记录数据行变化，更安全但日志更大
+ **MIXED**：两者结合，MySQL 默认设置

查看格式：

```sql
SHOW VARIABLES LIKE 'binlog_format';
```

主从同步就是靠 Binlog 实现的，主库写入操作会记录在 Binlog 中，从库会不断读取并重放这些日志。

---

## Redo 和 Binlog 的协作逻辑
InnoDB 的事务提交涉及两个系统：

1. Redo Log（物理日志）负责恢复
2. Binlog（逻辑日志）负责同步

为保证两边一致性，MySQL 引入了 **两阶段提交机制**：

1. 写入 Binlog
2. 写入 Redo Log，并提交事务

只有两者都写成功，事务才算真正提交。如果中途失败，MySQL 启动后会自动判断是否需要回滚或补交。

---

# 主从复制与高可用架构设计
## 什么是主从复制
主从复制（Replication）指的是：**一个主库负责写，从库负责读**，主库的数据变动通过日志传给从库，从库再“照着抄”。

这样能达到：

+ 分担读请求压力
+ 提升系统可用性（主库挂了还有从库）
+ 实现备份、归档、读写分离等目的

---

## 主从复制的核心流程
复制分为三步：

1. **主库写 Binlog**
2. **从库 IO 线程拉 Binlog**
3. **从库 SQL 线程执行 Binlog 中的操作**

这个过程叫 **异步复制**，意味着主库写完就完事，不等从库是否同步完。

也有半同步、全同步等模式，但需要额外配置插件或高版本支持。

---

## 复制方式有哪些？
MySQL 支持三种复制格式，对应 Binlog 的格式：

### 1. Statement-based（SBR）
+ 复制原始 SQL 语句
+ 简洁，但可能出现不一致（如非确定性函数）

### 2. Row-based（RBR）
+ 复制每行数据变动（如主键 id 从 1 变成 2）
+ 最精确，也最耗资源

### 3. Mixed-based（MBR）
+ 混合使用，根据情况选择 SBR 或 RBR
+ 是 MySQL 默认推荐方式

查看当前设置：

```sql
SHOW VARIABLES LIKE 'binlog_format';
```

---

## 设置主从的基本流程
以下是 MySQL 主从复制的基础步骤（简化）：

1. 主库开启 Binlog，并设置唯一 server-id

```plain
[mysqld]
server-id=1
log-bin=mysql-bin
```

1. 从库设置不同的 server-id

```plain
[mysqld]
server-id=2
```

1. 在主库创建复制账号：

```sql
CREATE USER 'repl'@'%' IDENTIFIED BY '123456';
GRANT REPLICATION SLAVE ON *.* TO 'repl'@'%';
```

1. 从库指定主库信息：

```sql
CHANGE MASTER TO
  MASTER_HOST='主库IP',
  MASTER_USER='repl',
  MASTER_PASSWORD='123456',
  MASTER_LOG_FILE='mysql-bin.000001',
  MASTER_LOG_POS=123;

START SLAVE;
```

1. 检查状态：

```sql
SHOW SLAVE STATUS\G
```

---

## 高可用架构的常见方式
### 单主多从 + 读写分离
+ 写操作集中在主库
+ 读操作分发到多个从库
+ 可以通过中间件实现（如 MyCat、ProxySQL、Atlas）

### MGR（Group Replication）
MySQL 官方推出的高可用方案，支持自动主从切换，事务强一致性，适合对数据同步非常敏感的业务。

### 双主复制（主主）
+ 两个节点互为主从
+ 可实现多点写入
+ 需要特别小心数据冲突（如自增主键）

---

## 故障切换方案设计
### 手动切换（最常见）
+ 运维通过监控发现主库异常
+ 提升一个从库为主库
+ 改变业务的连接配置

### 自动切换
+ 借助高可用组件如 **MHA**（MySQL High Availability）
+ 或 Kubernetes + StatefulSet 做自动恢复

自动化虽好，但也增加了复杂度和运维成本。

---

## 主从延迟的问题
从库复制是异步的，因此可能会出现延迟。表现为：

+ 主库刚写完数据，从库查不到
+ 某些业务逻辑依赖写后读就会出问题（比如下单后立即查订单）

解决方案：

+ 用读写分离中间件支持“读主”策略
+ 或在必要时手动读主库（比如订单类逻辑）

查看延迟时间：

```sql
SHOW SLAVE STATUS\G
-- 关注 Seconds_Behind_Master 字段
```

---

## 常见问题汇总
### 为什么主从会出现不一致？
+ 主库用了不确定函数（如 RAND(), UUID(), NOW()）
+ 手动修改了从库数据
+ 使用了 SBR 格式但 SQL 语义不稳定

建议使用 ROW 格式可避免多数问题。

### 如何避免主键冲突
双主架构下可能有主键冲突，这时可以使用奇偶数或步长策略，例如：

```sql
auto_increment_increment=2
auto_increment_offset=1  -- 主库1
auto_increment_offset=2  -- 主库2
```

### 从库宕机后还能追上吗
能。只要主库的 Binlog 还在，从库恢复后可继续同步。如果 Binlog 被清理，就需要重新做一次全量 + 增量同步。

---

# 读写分离
**MySQL 原生并不会自动把读请求分发到从库**，它只是提供了主从复制的能力，**读写分离是要自己做的**，通常通过以下3种方式实现。



**1. 应用层手动分发**

最常见也最灵活的做法，在业务代码中写明哪些操作走主库、哪些走从库。

例如：

+ 查询类接口走从库连接池
+ 写操作（新增、更新、删除）走主库连接池

优点：

+ 可控、灵活、便于定制（比如特定查询强制走主）

缺点：

+ 应用逻辑复杂度变高
+ 容易出现开发遗漏，导致数据不一致问题

****

**2. 中间件代理**

借助数据库中间件实现自动的读写分离路由：

+ **MyCat**
+ **ShardingSphere-Proxy**
+ **ProxySQL**
+ **Atlas（美团开源）**

它们的作用是作为“数据库代理层”，接收 SQL 请求，根据 SQL 类型自动判断读写，转发给主库或从库。

优点：

+ 与业务代码无耦合
+ 具备连接池、负载均衡等能力

缺点：

+ 配置复杂度略高
+ 性能取决于中间件本身

****

**3. 数据库驱动层支持（少见）**

部分语言的数据库驱动或 ORM 框架支持配置多个数据源，并自动根据查询类型路由。

如：

+ Spring Boot + MyBatis 可以配置多数据源
+ Laravel、Django 等也可以通过插件方式实现读写分离

不过这种方案本质上还是靠“程序逻辑”判断，没有数据库层的智能调度。



**延迟感知问题**

读写分离时还需要考虑 **主从延迟**：

+ 如果写完订单立刻查详情，查的是从库，可能还没同步到
+ 可能导致“刚写入就查不到”的现象

常见做法：

+ 核心流程强制读主（如订单/支付/登录）
+ 异步操作或非关键接口放宽一致性要求

---



