---
title: Redis
date: 2025-04-03
tags:
    - Redis
---

# I/O多路复用是什么

**I/O 多路复用**（I/O Multiplexing）是一种使得单个线程（或进程）能够同时监控多个 I/O 操作的技术，它可以让程序有效地处理多个 I/O 操作（如读取文件或网络连接）而无需为每个操作创建一个独立的线程或进程。I/O 多路复用的核心思想是在一个线程内，能够同时处理多个 I/O 操作，避免了频繁的线程切换和进程创建，从而提高了系统的性能和资源利用率。

在没有 I/O 多路复用机制的情况下，当程序需要等待多个 I/O 操作时（比如等待多个网络连接的读取操作），通常会采取阻塞方式，直到每个操作完成。这样每个操作都会阻塞当前线程，导致系统资源浪费。I/O 多路复用通过在一个线程内同时监听多个 I/O 操作，使得线程在等待 I/O 操作完成时可以继续做其他工作。

## I/O 多路复用的工作原理
I/O 多路复用的基本原理是，程序通过一个系统调用（如 `select`、`poll`、`epoll` 等）将多个文件描述符注册到内核中，内核在这些文件描述符上的 I/O 事件发生时通知程序。程序通过查询这些文件描述符的状态，确定哪些可以进行读写操作。

具体流程如下：

1. **注册文件描述符**：应用程序通过某种方式（如 `select`、`poll`、`epoll` 等）将需要监控的文件描述符注册到操作系统内核。
2. **等待 I/O 事件**：应用程序进入等待状态，等待内核通知哪些文件描述符有事件（例如数据可读、可写或异常）。
3. **事件发生时处理 I/O 操作**：一旦某个文件描述符有 I/O 事件发生，内核会通知程序，程序可以读取或写入数据，或处理相应的 I/O 操作。
4. **重复等待**：程序处理完事件后，继续进入等待状态，直到下一个事件发生。

## 为什么需要 I/O 多路复用？
I/O 多路复用的目标是提高并发性和系统性能，尤其是在以下几种场景下：

1. **高并发**：当需要同时处理大量 I/O 操作（比如网络请求、文件操作等）时，创建一个线程或进程来处理每个请求可能会消耗大量系统资源，而 I/O 多路复用通过共享一个线程来处理多个 I/O 操作，大大减少了资源消耗。
2. **减少阻塞**：传统的 I/O 操作通常是阻塞的，程序会一直等待 I/O 操作完成，直到可以读取或写入数据。而 I/O 多路复用使得程序在等待 I/O 操作时不会被阻塞，可以同时处理多个 I/O 请求，提高效率。
3. **资源节省**：通过单线程处理多个 I/O 操作，可以避免过多的线程或进程创建，从而节省系统资源，减少上下文切换的开销。

## I/O 多路复用的典型技术
I/O 多路复用的实现方式依赖于操作系统提供的系统调用，常见的实现技术包括：

1. `**select**`：
    - 最早期的 I/O 多路复用机制，允许程序监控多个文件描述符，判断哪些文件描述符已经准备好进行读写操作。
    - `select` 通过传递文件描述符集合来实现，每次调用都会检查所有文件描述符的状态，因此在大量文件描述符的情况下性能会变差。
    - 受限于文件描述符数量（通常是 1024）。
2. `**poll**`：
    - 类似于 `select`，但解决了 `select` 的一些局限，比如文件描述符数量的限制。
    - `poll` 使用一个数组来存储文件描述符和事件，能处理任意数量的文件描述符，但性能仍然随着文件描述符数量的增加而降低。
3. `**epoll**`：
    - Linux 下提供的高效 I/O 多路复用机制，特别适用于处理大量并发连接。
    - `epoll` 使用事件驱动的方式，只关注那些发生事件的文件描述符，避免了不必要的检查和遍历，从而提高了性能。
    - 支持边缘触发（ET）和水平触发（LT）模式，能够更精确地控制 I/O 事件。
    - `epoll` 有两种工作模式：
    1. **水平触发（Level Triggered，LT）**：
        * 当某个文件描述符有数据可读时，`epoll` 会通知用户程序。如果程序没有读走所有数据，它会继续通知直到数据被完全读取。
    2. **边缘触发（Edge Triggered，ET）**：
        * 当某个文件描述符的状态从不可读变为可读时，`epoll` 会通知用户程序。只有当文件描述符的状态发生变化时，`epoll` 才会触发通知。相比于 LT 模式，ET 模式需要程序更精细地处理数据。
4. `**kqueue**`（在 BSD 系统中）：
    - 类似于 `epoll`，是 BSD 系统（如 macOS）中的 I/O 多路复用机制。`kqueue` 能高效地监控多个 I/O 事件，支持灵活的事件处理机制。

## I/O 多路复用的优缺点
### 优点
1. **高并发处理**：在单线程或少量线程中处理多个 I/O 操作，避免了线程和进程切换的开销，能处理更多的并发请求。
2. **节省资源**：减少了线程和进程的创建和销毁，避免了过多的资源消耗。
3. **避免阻塞**：通过非阻塞的 I/O 操作，程序能够在等待数据时继续执行其他任务，提升系统响应能力。

### 缺点
1. **实现复杂**：相比传统的阻塞式 I/O，I/O 多路复用需要处理更多的复杂性，如事件的管理和响应。
2. **适用场景有限**：虽然 I/O 多路复用适用于高并发场景，但它对于一些不需要处理大量并发的简单应用来说可能过于复杂。
3. **系统依赖性**：不同操作系统提供的 I/O 多路复用机制（如 `select`、`poll`、`epoll`）有差异，可能需要考虑跨平台的适配问题。

---

# redis都有哪些数据结构
Redis 提供了多种数据结构，旨在帮助开发者高效地存储和操作不同类型的数据。每种数据结构在 Redis 中都扮演着不同的角色，针对特定的应用场景进行优化。以下是 Redis 支持的主要数据结构：

## 1. String（字符串）
+ **描述**：Redis 中的基本数据类型，可以存储任何类型的字符串，包括数字、文本、二进制数据等。
+ **特点**：
    - 每个键值对中的值都是一个字符串，最大长度为 512 MB。
    - 支持常见的字符串操作，如设置、获取、拼接、截取等。
    - 用途广泛，适合存储缓存、会话信息、计数器等。
+ **常见操作**：
    - `SET key value`：设置键值对。
    - `GET key`：获取键对应的值。
    - `INCR key`：对值进行加 1 操作（计数器）。

## 2. List（列表）
+ **描述**：一个简单的字符串列表，按照插入顺序排序，可以在列表的两端进行推送、弹出等操作。
+ **特点**：
    - 支持从左侧或右侧操作（即双端队列）。
    - 适合队列、栈等数据模型。
    - 支持基于索引的访问和范围查询。
+ **常见操作**：
    - `LPUSH key value`：将值推入列表的左端。
    - `RPUSH key value`：将值推入列表的右端。
    - `LPOP key`：从左侧弹出一个元素。
    - `RPOP key`：从右侧弹出一个元素。
    - `LRANGE key start stop`：返回列表指定范围内的元素。

## 3. Set（集合）
+ **描述**：无序的字符串集合，集合中的元素是唯一的，没有重复值。
+ **特点**：
    - 支持集合操作，如交集、并集和差集等。
    - 适合用来存储不允许重复的数据。
    - 常用于标签、集合运算等。
+ **常见操作**：
    - `SADD key member`：将成员添加到集合中。
    - `SREM key member`：移除集合中的成员。
    - `SMEMBERS key`：返回集合中的所有成员。
    - `SINTER key1 key2`：返回两个集合的交集。

## 4. Sorted Set（有序集合）
+ **描述**：与 Set 类似，但每个元素都有一个分数（score），根据分数进行排序。
+ **特点**：
    - 元素按照分数从小到大排序，且分数相同的元素会按照插入顺序排序。
    - 支持范围查询，可以根据分数范围进行查询，适用于排行榜、延迟队列等场景。
+ **常见操作**：
    - `ZADD key score member`：将元素及其分数添加到有序集合中。
    - `ZRANGE key start stop`：返回指定区间内的元素。
    - `ZREM key member`：移除有序集合中的成员。
    - `ZRANK key member`：返回成员的排名。

## 5. Hash（哈希）
+ **描述**：键值对集合，适合存储对象类型的数据。哈希可以通过字段（field）来存储多个值。
+ **特点**：
    - 每个哈希可以包含多个字段和相应的值，类似于一个对象或记录。
    - 适合存储多个关联字段的数据（例如，用户信息）。
+ **常见操作**：
    - `HSET key field value`：为哈希添加一个字段和值。
    - `HGET key field`：获取哈希中指定字段的值。
    - `HGETALL key`：获取哈希中的所有字段和值。
    - `HDEL key field`：删除哈希中的指定字段。

## 6. Bitmaps（位图）
+ **描述**：位图是对字符串类型的一种扩展，可以将字符串的每一位作为一个独立的 bit（0 或 1）来使用。
+ **特点**：
    - 适用于高效的布尔值集合操作，比如用户是否参与活动。
    - 可以在不需要额外内存的情况下存储大量的布尔值。
+ **常见操作**：
    - `SETBIT key offset value`：在指定位置设置位值。
    - `GETBIT key offset`：获取指定位置的位值。
    - `BITCOUNT key`：统计指定键中为 1 的位数。

## 9. Streams（流）
+ **描述**：Redis Streams 是一个类似消息队列的数据结构，用于存储和处理消息流。
+ **特点**：
    - 支持按时间戳存储消息，并支持消费者组（Consumer Groups）。
    - 可用于构建类似 Kafka 的消息队列系统。
+ **常见操作**：
    - `XADD key * field value`：向流中添加一条消息。
    - `XREAD`：从流中读取消息。
    - `XGROUP CREATE`：创建消费者组。

## 总结
Redis 提供了非常丰富和高效的数据结构，适用于各种不同的使用场景。根据不同的需求，你可以选择合适的数据结构来存储和处理数据：

+ **String**：适用于缓存、计数器等简单数据。
+ **List**：适合队列、栈等线性数据。
+ **Set**：用于去重、集合操作等。
+ **Sorted Set**：适合排行榜、延迟队列等按顺序操作的数据。
+ **Hash**：适合存储对象或多字段的数据。
+ **Bitmaps**：适用于位级操作。
+ **Streams**：适用于消息队列等场景。

这些数据结构可以帮助开发者根据实际需求进行灵活的设计与优化，使得 Redis 成为一个非常强大的数据存储系统。

| 类型 | 特点 | 场景 |
| --- | --- | --- |
| String | 快速简单，最大512MB | 缓存单值、计数器、Token |
| Hash | 结构体对象存储 | 用户信息、配置项 |
| List | 有序双向链表 | 消息队列、日志 |
| Set | 无序唯一集合 | 去重、标签、集合运算 |
| ZSet | 有序集合，带权重 | 排行榜、延迟队列 |


---

# Redis 是单线程的，为什么还能这么快？单线程不是慢吗？
1. 所有数据在内存中，访问没有磁盘 IO
2. 单线程模型，避免上下文切换和加锁开销
3. 基于 epoll 的 IO 多路复用，处理高并发连接
4. 简单高效的数据结构（C实现 + ziplist/intset优化）

---

# 项目中用过哪些 Redis 的数据结构？为什么不用关系型数据库
+ 用过 String（缓存用户Token）、Hash（缓存用户详情）、List（异步消息）、ZSet（排行榜）
+ Redis 内存操作速度远高于关系型数据库，用于热点数据加速
+ 没有事务性强要求场景时，Redis 几毫秒的响应速度是数据库无法比的

---

# Redis的过期机制和内存淘汰策略
## 一、Key 的过期机制（TTL）
Redis 支持设置每个 key 的**过期时间**，到时间后自动删除。

### 🔹设置过期时间的命令
```bash
SET user:1 "Tom" EX 60     # 设置 60 秒后过期
EXPIRE user:1 60           # 单独设置过期时间
TTL user:1                 # 查询剩余时间
```

### Redis 什么时候删除这些 key？
重点：**不是精确时钟删除，而是惰性 + 定期删除机制组合**

### 删除策略详解
1. **惰性删除（Lazy）**
    - 客户端访问 key 时，Redis 发现已过期，就立刻删掉（并返回 nil）
2. **定期删除（主动扫描）**
    - 每 100ms，Redis 会**随机抽样一批带过期时间的 key**，删除过期的
    - 如果发现超 25% 的 key 都过期了，就**加快扫描节奏**

### 为什么不逐个精准定时删除？
会造成高 CPU 负载，扫描量大，Redis 单线程承受不住

---

## 二、内存淘汰机制（Memory Eviction）
当 Redis 达到设置的最大内存（`maxmemory`），又需要写入新 key 时，会触发**淘汰机制**。

```bash
# 配置示例
maxmemory 512mb
maxmemory-policy allkeys-lru
```

---

### 常见的内存淘汰策略
| 策略名 | 含义 | 推荐使用场景 |
| --- | --- | --- |
| noeviction | 默认值，不淘汰，写入时报错 | 不建议线上使用 |
| volatile-lru | 从**有过期时间的 key 中**淘汰最少使用的 | 有效控制热数据内存 |
| allkeys-lru | 所有 key 中淘汰最少使用的 | 推荐：缓存场景 |
| volatile-ttl | 从有过期时间的 key 中淘汰**快过期的** | 延迟淘汰控制 |
| allkeys-random | 所有 key 中随机淘汰 | 一般用作测试 |
| volatile-random | 有过期时间的 key 中随机淘汰 | 比较少用 |


---

### Redis 设置了 maxmemory 和淘汰策略，为什么还是 OOM 了？
1. 设置的是 `noeviction`，没有开启淘汰功能
2. 有大量 key 没设置 TTL，策略是 `volatile-*`，Redis 找不到 key 可以淘汰
3. 有大 key（bigkey），触发淘汰时清理不及时
4. 写入速度远超淘汰速度（高并发写入 + 单线程处理）

---

## 实战建议
| 建议 | 理由 |
| --- | --- |
| key 必须设置 TTL | 防止缓存雪崩，内存泄露 |
| 建议使用 allkeys-lru | 更加自动化地控制内存 |
| 避免存大 key（如超大 hash、list） | 淘汰慢、容易卡主线程 |
| 监控 Redis 内存使用 | 用 `INFO MEMORY`<br/> 或 `redis_exporter`<br/> 上 Prometheus 监控 |


---

## 自问自答
1. Redis 的过期 key 是怎么删除的？是实时的吗？ 不是实时的， 惰性+定期
2. Redis 的惰性删除和定期删除分别是什么？ 
3. Redis 的内存淘汰策略有哪些？哪个最常用？
4. 如果写入大量 key，但内存没满 Redis 就挂了，可能的原因有哪些？ 有设置最大内存， 或者是过多内存碎片，  或者是有写入大key，导致CPU撑不住卡主进程了.....
5. 项目中怎么控制 Redis 占用内存？  设置`**maxmemory**`**、内存回收策略、过期时间控制**

---

# 缓存穿透、缓存击穿、缓存雪崩
## 缓存穿透
### 问题描述
客户端频繁请求**数据库中根本不存在的 key**，由于缓存 miss，Redis 不命中，所有请求都落到底层数据库，造成数据库压力激增，甚至打挂。

### 典型场景
请求不存在的用户 ID，比如 `GET user:-1`，Redis miss，数据库 miss，不断重复请求。

### 解决方案
1. **缓存空值**
    - 对于数据库返回 null 的数据，也缓存一个标记，例如：`user:-1 => "null"`，设置较短过期时间。
2. **布隆过滤器（BloomFilter）**
    - 在 Redis 之前做一层布隆过滤器，用于快速判断 key 是否存在，避免无意义请求。
3. **接口参数校验**
    - 提前在 API 层做参数合法性校验，比如 ID 必须 > 0。

---

## 缓存击穿
### 问题描述
一个**热点 key 恰好过期**，大量并发请求在这个瞬间同时打到数据库，造成数据库压力瞬时激增。

### 典型场景
某商品详情是热点，每秒几千请求，刚好 `GET product:123` 在某个时刻过期，所有请求瞬间穿透。

### 解决方案
1. **互斥锁（分布式锁）**
    - 第一个请求获取锁去加载数据，其它请求等待或短时间返回旧数据。
2. **永不过期 + 异步刷新**
    - 不设置过期时间，而是定时刷新缓存（通过定时任务或消息队列）。
3. **合理设置过期时间 + 提前异步预热**
    - 对热点 key 使用更长过期时间，或者在过期前预热。

---

## 缓存雪崩
### 问题描述
大量 key 在同一时刻同时失效，所有请求同时穿透，数据库被压垮。

### 典型场景
比如你缓存设置了 1 小时统一过期，某一时刻恰好全部失效，系统瞬间崩溃。

### 解决方案
1. **过期时间加随机扰动**
    - 给每个 key 设置不同的过期时间，避免同一时间集中失效。例如 `EX 600 + random(0~60)`。
2. **热点数据永不过期 + 后台异步刷新**
3. **降级保护机制**
    - 当发现缓存异常，短路请求，直接返回默认值、静态页等。

---

## 自问自答
1. 什么是缓存穿透？怎么解决？
2. 缓存击穿和穿透的区别是什么？
3. 怎么解决 Redis 大量 key 同时过期的雪崩问题？
4. 使用 Redis 做缓存时，是否建议 key 永久有效？
5. 有没有用过布隆过滤器？什么原理？ 是个概率性的数据结构， 用多个不同的哈希算法， 拿到的哈希值如果对应的都是1， 就是1， 只要有一个是0， 就是0， 因此存的数据量越大， 越容易误报



# Redis的持久化机制（RDB 与 AOF）
Redis 虽然是内存数据库，但为了防止数据丢失，提供了两种持久化机制：**RDB**（快照）和 **AOF**（追加日志）。

---

## 持久化方式概览
| 类型 | 全称 | 特点 | 数据安全性 | 文件大小 | 启动速度 |
| --- | --- | --- | --- | --- | --- |
| RDB | Redis DataBase snapshot | 定期快照 | 较低 | 小 | 快 |
| AOF | Append Only File | 日志追加 | 高 | 大 | 慢（需重放） |
| 混合模式 | RDB + AOF | Redis 4.0 后默认 | 综合优点 | 可控 | 快速恢复 |


---

## RDB（快照方式）
### 原理
+ Redis 在一定时间间隔内将内存数据写入一个压缩过的二进制文件（`.rdb`）
+ 触发方式：
    - 自动：配置 `save 900 1`（900 秒内至少 1 个 key 变动）
    - 手动：执行 `SAVE` 或 `BGSAVE` 命令

### 优点
+ 启动恢复速度快
+ 文件体积小，适合备份、灾备迁移

### 缺点
+ 可能丢失最近一次修改（最后一次快照之后的数据）
+ BGSAVE 会 fork 子进程，写入大文件时会造成系统负载升高

---

## AOF（日志方式）
### 原理
+ 所有写命令会追加到 `.aof` 文件中，Redis 重启时按顺序“重放命令”恢复数据
+ 三种刷盘策略（由 `appendfsync` 决定）：
    - always：每次写都刷盘（最安全，最慢）
    - everysec：每秒刷一次（默认）
    - no：由操作系统决定（可能丢失几秒）

### 优点
+ 数据恢复更完整（最多丢失 1 秒）
+ 适合对数据完整性要求高的场景

### 缺点
+ 文件越来越大，需要定期重写（BGREWRITEAOF）
+ 启动时需要重放日志，恢复速度比 RDB 慢

---

## 混合持久化（Redis 4.0+）
### 原理
+ 在 AOF 重写时，先将当前快照（RDB 格式）写入 AOF，然后再追加后续写命令
+ 好处：
    - 启动速度几乎和 RDB 一样快
    - 数据完整性和 AOF 一样高

### 开启方式
```bash
aof-use-rdb-preamble yes
```

---

## 配置示例
```bash
save 900 1
appendonly yes
appendfsync everysec
dir /var/lib/redis
```

---

## 自问自答
1. Redis 持久化有几种方式？分别适用于什么场景？
2. 如果 Redis 宕机了，数据怎么恢复？会不会丢数据？
3. RDB 和 AOF 哪个恢复速度更快？哪个更安全？
4. 怎么避免 RDB/AOF 持久化造成主线程卡顿？

---

## 实战建议
| 建议 | 理由 |
| --- | --- |
| 开启 AOF + everysec 模式 | 实现安全性和性能的平衡 |
| 配置 save 900 1 等参数 | 保留定期快照，便于快速恢复 |
| 设置 aof-use-rdb-preamble yes | 兼顾快速启动与完整性 |
| 使用 Redis 主从 + 持久化 | 容灾架构更稳妥 |


# Redis 是怎么做 AOF 重写的？会不会影响性能？
在 Redis 中，**AOF（Append Only File）重写** 是一种用于优化磁盘 I/O 和 AOF 文件大小的机制。AOF 重写是 Redis 在持久化数据时采取的一种方式，目的是定期生成新的 AOF 文件，从而减少旧文件的大小并提高性能。

### **什么是 AOF 重写？**
Redis 使用 AOF 持久化机制时，会将所有的写命令记录到 AOF 文件中，这样即使 Redis 重启，数据也不会丢失。随着时间的推移，AOF 文件可能会变得非常大，尤其是在有大量写操作的场景下。为了避免 AOF 文件过大，Redis 提供了 **AOF 重写（AOF rewrite）** 机制。

AOF 重写是指 Redis 会创建一个新的 AOF 文件，只记录 **当前数据库状态** 的最简写操作，从而生成一个更小的文件。这个过程不会影响 Redis 正常的写操作，但会在后台进行，保证 Redis 在重写期间继续为客户端提供服务。

### **AOF 重写的工作原理**
1. **触发条件**：
    - AOF 重写通常由 Redis 根据 AOF 文件的大小和重写条件来触发。重写会在 Redis 认为 AOF 文件过大时自动进行，或者也可以通过手动调用 `BGREWRITEAOF` 命令来触发。
2. **重写过程**：
    - 在 AOF 重写过程中，Redis 会创建一个新的 AOF 文件，并在后台 **重新生成** AOF 文件中的命令。这个过程会记录所有当前数据库状态所需的最小写命令。
    - 比如，如果数据库中某个键的值已经改变了多次，Redis 会将该键的最终状态写入新的 AOF 文件，而不再记录每次对该键的修改操作。
3. **AOF 重写的工作步骤**：
    - **步骤 1**：Redis 在后台创建一个新的 AOF 文件，并逐个遍历数据库中的所有键，生成一组命令来重新构建当前数据库的状态。
    - **步骤 2**：当新的 AOF 文件创建完成后，Redis 会将当前 AOF 文件中的所有命令写入新文件中，确保新文件包含了数据库的最新状态。
    - **步骤 3**：一旦新的 AOF 文件完成，Redis 会关闭原来的 AOF 文件，将新的文件替换为当前 AOF 文件。
4. **后台执行**：
    - 在进行 AOF 重写时，Redis 会使用 **后台（fork）** 的方式创建一个子进程来执行重写操作。这个子进程会处理数据的写入，不会影响主进程的运行。
    - 这种方式允许 Redis 在 AOF 重写期间继续服务客户端请求，保证了系统的高可用性。

### **AOF 重写是否会影响性能？**
AOF 重写的过程是通过 **fork 子进程** 来执行的，因此在执行重写时，Redis 主进程可以继续服务客户端请求。但是，AOF 重写操作还是会对性能产生一定的影响，具体体现在以下几个方面：

1. **内存占用**：
    - 在 AOF 重写期间，Redis 会在后台创建一个子进程，并复制主进程的内存空间。这意味着在重写过程中，Redis 的内存使用量会增加，因为它需要同时保持原有的 AOF 文件和新的 AOF 文件内容。对于内存较小的机器，这可能会导致内存使用高峰。
2. **CPU 占用**：
    - AOF 重写需要扫描整个数据库，并生成新的 AOF 文件，这会消耗一定的 CPU 资源。虽然 Redis 会在后台执行这一过程，但在大数据量的情况下，CPU 的负载可能会暂时增高。
3. **磁盘 I/O**：
    - AOF 重写会生成新的 AOF 文件，并将新的命令写入磁盘。这会增加磁盘的写入压力。如果磁盘性能较差或 I/O 较高的场景下，可能会对性能产生影响。
4. **阻塞时间**：
    - 在某些情况下，尤其是当 AOF 文件非常大，或者当系统资源有限时，AOF 重写可能会导致 Redis 的响应时间略微增加，特别是在频繁触发 AOF 重写时。
5. **fork 子进程的影响**：
    - Redis 使用 `fork` 创建子进程来执行 AOF 重写操作，而 `fork` 操作会占用一定的系统资源。虽然子进程会在重写完成后被销毁，但在 `fork` 的过程中，操作系统需要进行内存页的复制，这会消耗 CPU 和内存资源。

### **如何减少 AOF 重写对性能的影响？**
为了减少 AOF 重写对性能的影响，可以采取以下策略：

1. **合理设置 **`**auto-aof-rewrite-percentage**`** 和 **`**auto-aof-rewrite-min-size**`：
    - `auto-aof-rewrite-percentage`：控制触发 AOF 重写的条件。它设置为相对于上次重写时 AOF 文件的大小增长百分比。
    - `auto-aof-rewrite-min-size`：控制 AOF 文件的最小大小，只有当文件大小超过这个值时，才会考虑执行 AOF 重写。

通过合理配置这两个参数，可以控制 AOF 重写的触发频率，从而避免频繁的 AOF 重写操作，减小对性能的影响。

```bash
auto-aof-rewrite-percentage 100  # AOF 文件大小增加 100% 后进行重写
auto-aof-rewrite-min-size 64mb  # AOF 文件超过 64MB 时才进行重写
```

2. **使用合适的硬件资源**：
    - 如果可能，考虑为 Redis 配置更高性能的硬件，尤其是 I/O 密集型的存储设备（如 SSD）。更强大的硬件可以显著减少 AOF 重写过程中对磁盘 I/O 的压力。
3. **优化 **`**maxmemory-policy**`** 配置**：
    - 在 Redis 中设置合理的内存回收策略，确保内存不会过度占用，避免因内存不足导致频繁的 AOF 重写。
4. **分批写入数据**：
    - 对于大量写入数据的场景，考虑将数据写入 Redis 时分批处理，减少瞬时写入压力，降低 AOF 文件增长速度。
5. **使用 AOF + RDB 混合持久化（RDB + AOF）**：
    - Redis 还支持同时使用 **RDB（快照）** 和 **AOF** 两种持久化方式，您可以通过配置 Redis 在一定间隔内执行快照（RDB）保存，并在更高频次下执行 AOF 持久化。这可以减小对性能的影响，同时保证数据持久化。

```bash
# 启用 RDB 和 AOF 混合持久化
appendonly yes
appendfsync everysec
save 900 1
save 300 10
save 60 10000
```

### **总结**
AOF 重写是 Redis 为了优化 AOF 文件大小、提高性能和减少磁盘 I/O 而采取的机制。虽然 AOF 重写通常是在后台进行，不会阻塞主进程，但它确实会消耗一些额外的 CPU 和内存资源，尤其是在大数据量的情况下。因此，合理的配置和硬件资源的支持是确保 AOF 重写不会对性能产生过大影响的关键。

---

# 怎么避免 RDB/AOF 持久化造成主线程卡顿
在 Redis 中，RDB 和 AOF 是两种常见的持久化机制，它们会定期将内存中的数据持久化到磁盘，确保数据的持久性。但这两个过程可能会造成一定的 **主线程卡顿**，特别是在大规模数据存储或高并发环境下，RDB 和 AOF 持久化过程会占用大量的 CPU 和 I/O 资源，从而影响 Redis 的响应速度和性能。

下面是一些避免 RDB/AOF 持久化造成主线程卡顿的方法

## 1. 使用 RDB 快照时采用后台保存（`save` 和 `BGSAVE`）
+ 默认情况下，Redis 使用 `**BGSAVE**`（背景保存）来执行 RDB 快照操作。`BGSAVE` 会在后台创建一个子进程，主线程继续服务客户端请求。
+ `BGSAVE` 操作不会阻塞主线程，它通过 `fork()` 子进程的方式执行，因此可以在不影响 Redis 主线程的情况下进行持久化。
+ **注意**：如果在 Redis 配置中使用 `**save**` 命令来设置 RDB 快照（比如每隔 900 秒进行一次快照），如果在执行 RDB 时不使用 `BGSAVE`，则会导致 **阻塞**，因为此时 Redis 主线程会被锁定，直到 RDB 快照完成。

**配置**：

```bash
# RDB 快照配置示例
save 900 1
save 300 10
save 60 10000
```

在 `BGSAVE` 执行期间，主线程仍然可以继续处理客户端请求。

## 2. 合理配置 AOF 持久化
AOF（Append Only File）将 Redis 执行的所有写操作追加到 AOF 文件中，以保证持久化数据。AOF 的同步策略（`appendfsync`）决定了每次写入操作是如何同步到磁盘的：

+ `**appendfsync always**`：每次写操作都会同步到磁盘，性能最低，通常不推荐。
+ `**appendfsync everysec**`：每秒同步一次。是推荐的设置，性能和数据持久性之间有一个良好的平衡。
+ `**appendfsync no**`：让操作系统决定何时将数据同步到磁盘，性能最高，但在系统崩溃时可能会丢失一些数据。

**推荐设置**：

```bash
appendonly yes
appendfsync everysec  # 每秒钟一次同步到磁盘
```

`appendfsync everysec` 可以最大限度减少 AOF 持久化对主线程的影响，同时确保数据的持久性。

## 3. 启用 AOF 重写机制
AOF 文件随着时间的推移会变得越来越大，这样会导致持久化操作变得非常慢，影响 Redis 的性能。为了防止 AOF 文件过大导致性能下降，Redis 提供了 **AOF 重写（AOF rewrite）** 机制。

**AOF 重写** 的过程是将当前数据库的状态重新写入 AOF 文件，并且会创建一个新的 AOF 文件，而不记录所有历史操作。AOF 重写是通过一个后台进程来完成的，因此它不会影响主线程。

**AOF 重写的触发条件**：

+ 当 AOF 文件的大小超出一定比例时（默认是 100%）。
+ 可以通过配置 `auto-aof-rewrite-percentage` 和 `auto-aof-rewrite-min-size` 来控制触发条件。

**配置示例**：

```bash
# 自动触发 AOF 重写的条件
auto-aof-rewrite-percentage 100  # 当 AOF 文件大小增加 100% 时触发重写
auto-aof-rewrite-min-size 64mb  # 当 AOF 文件超过 64MB 时触发重写
```

通过合理配置 AOF 重写，Redis 可以自动优化 AOF 文件的大小，避免在文件过大的时候影响性能。

## 4. 优化磁盘 I/O 性能
RDB 和 AOF 持久化操作都涉及到磁盘 I/O，因此磁盘性能对于持久化的效率至关重要。使用更快的存储设备（例如 SSD）可以显著提高持久化过程的性能，减少对主线程的影响。

**优化建议**：

+ 使用 **SSD**（固态硬盘）而不是传统的 **HDD**（机械硬盘），以减少磁盘 I/O 的延迟。
+ 将 Redis 的数据目录和 AOF 文件存储在不同的物理磁盘上，避免磁盘 I/O 竞争。
+ 通过 `**vm.dirty_background_bytes**` 等内核参数来调整操作系统的 I/O 调度策略，优化磁盘写入效率。

## 5. 定期执行 `MEMORY PURGE` 清理内存碎片
当 Redis 进行大量写入和持久化时，内存碎片可能导致内存管理效率低下，从而影响 Redis 性能。使用 `**MEMORY PURGE**` 命令可以清理 Redis 中的内存碎片，释放无用内存，从而减少内存使用和提高性能。

```bash
MEMORY PURGE  # 清理内存碎片
```

定期执行内存清理操作有助于减轻持久化时的内存负担，从而改善 Redis 性能。

## 6. 使用混合持久化（RDB + AOF）
Redis 支持混合持久化，即同时使用 **RDB 和 AOF**。通过这种方式，Redis 可以在启动时使用 RDB 快照来恢复数据，而在写操作时使用 AOF 进行持久化。混合持久化通过减少 AOF 文件的大小来优化性能，并提高 Redis 的启动速度。

**启用混合持久化**：

```bash
appendonly yes
appendfsync everysec
rdbchecksum yes
```

混合持久化的优势是，在不牺牲持久化的可靠性和完整性的情况下，通过 AOF 重写和 RDB 快照的结合来减少磁盘 I/O 的压力。

## 总结
为了避免 RDB 和 AOF 持久化造成 Redis 主线程卡顿，可以采取以下措施：

1. **使用 **`**BGSAVE**` 执行 RDB 快照，避免阻塞主线程。
2. **合理配置 AOF 持久化策略**（推荐 `appendfsync everysec`）来平衡性能和持久性。
3. **利用 AOF 重写** 来减少 AOF 文件的大小，避免性能下降。
4. **优化磁盘 I/O 性能**，使用 SSD 或更快的存储设备来提高持久化效率。
5. **定期清理内存碎片**，通过 `MEMORY PURGE` 来减轻内存管理负担。
6. **使用混合持久化**（RDB + AOF）来提升性能，减少 AOF 文件大小。

通过这些方法，您可以减少 RDB 和 AOF 持久化对 Redis 性能的影响，提高系统的响应速度和可用性。



# Redis是怎么存储有序集合zset的
**Redis 的 ZSet（有序集合）**，它在 Redis 中扮演着非常核心的角色，特别适用于排行榜、延时队列、权重调度等场景。

---

## 什么是 ZSet（Sorted Set）
ZSet 是 Redis 中的一种数据结构，全称是 **有序集合（Sorted Set）**。

它的特点是：

+ 每个元素都是唯一的（像 Set）
+ 每个元素关联一个 **score**（分数），按 score 排序（像优先队列）
+ 可以按分数范围、高低排名、高低分数做高效查询

你可以把 ZSet 看成是：  
**带权重的 Set + 排序链表 + 快速查找结构**

---

## 数据结构实现：跳表 + 哈希表
### ZSet 底层用了两个结构：
1. **哈希表（dict）**
    - 快速定位元素对应的 score
    - key 是元素，value 是 score
2. **跳表（skiplist）**
    - 维持元素按 score 升序排列
    - 用于支持范围查找、区间遍历、按排名查询等

为什么用跳表而不是红黑树？

+ 插入/删除逻辑简单
+ 查询效率也接近 O(log n)
+ Redis 追求极致性能，跳表是工程中性能 + 简洁度权衡最佳的结构

---

## 核心操作和性能
| 操作 | 命令 | 时间复杂度 | 说明 |
| --- | --- | --- | --- |
| 添加/更新元素 | `ZADD key score member` | O(log n) | 插入或更新元素，跳表中调整顺序 |
| 删除元素 | `ZREM key member` | O(log n) | 删除成员，同时从 dict 和 skiplist 删除 |
| 查询成员的分数 | `ZSCORE key member` | O(1) | 直接从 dict 中查 |
| 按排名查成员 | `ZRANGE key start stop` | O(log n + m) | 从跳表中按顺序取元素 |
| 查某个成员的排名 | `ZRANK key member` | O(log n) | 在跳表中向下查找节点，统计 rank |
| 范围删除 | `ZREMRANGEBYSCORE key min max` | O(log n + m) | 从跳表中范围定位，然后批量删除 |
| 分数区间查找 | `ZRANGEBYSCORE key min max` | O(log n + m) | 先用跳表查 min，再往后遍历 |
| 获取总数 | `ZCARD key` | O(1) | 获取元素个数 |
| 获取某 score 范围内的个数 | `ZCOUNT key min max` | O(log n) | 范围查找后累加统计 |


其中 `m` 表示范围内返回的元素数量。

---

## 跳表结构内部逻辑（示意）
以一个 ZSet 示例：

```bash
ZADD z 5 alice
ZADD z 10 bob
ZADD z 7 tom
ZADD z 1 kate
```

跳表结构会长成这样（层数为随机生成的）：

```plain
Level 3:            bob
Level 2:      tom - bob
Level 1: kate - tom - alice - bob
```

每一层是有序链表，底层记录所有元素，查询从顶层开始，逐层往下，最终在底层找到目标。

---

## 应用场景举例
### 排行榜（经典）
```bash
ZADD game 1000 user1
ZADD game 950 user2
ZADD game 1200 user3
ZRANGE game 0 -1 WITHSCORES   # 按分数升序输出所有玩家
ZREVRANK game user1           # 查看 user1 的排名（倒序）
```

### 延时队列
用 score 表示未来的执行时间戳：

```bash
ZADD task_queue 1680000000 task_id_123
ZRANGEBYSCORE task_queue 0 1680001000 LIMIT 0 1
# 查当前需要执行的任务
```

### 动态权重调度（比如任务优先级）
score 表示优先级，值越小优先级越高：

```bash
ZADD job 1 job1
ZADD job 3 job2
ZRANGE job 0 0        # 获取优先级最高的任务
ZREM job job1         # 删除执行完成的任务
```

---

## 与 List、Set、Hash 的对比
| 结构 | 是否排序 | 是否支持范围查找 | 插入/查找复杂度 | 用途 |
| --- | --- | --- | --- | --- |
| List | 按插入顺序 | 支持（按位置） | O(1)/O(n) | 消息队列 |
| Set | 无序 | 不支持 | O(1) | 唯一元素集合 |
| ZSet | 按 score 排序 | 支持 | O(log n) | 排行榜、延迟队列 |
| Hash | 无序 | 不支持 | O(1) | 映射结构 |


---

## 内存占用注意事项
ZSet 中的跳表节点比较复杂，包含：

+ 元素值（字符串）
+ score（double）
+ 多级 forward 指针
+ span 用于计算 rank

如果元素很多、节点层数高，跳表的内存占用会比普通链表/集合大，需要注意评估。

---

## 总结
+ ZSet 是 Redis 提供的**有序集合结构**
+ 底层是 **哈希表 + 跳表** 的组合，既支持快速定位，也支持按顺序遍历
+ 提供排名、区间删除、分数查找、范围扫描等高级操作
+ 实现简单、查询快、非常适合排行榜、权重调度、定时任务等场景
+ 是 Redis 中最具代表性的高性能数据结构之一

好的，我们进入 Redis 学习的第五讲，讲解：

---

# Redis 的主从复制与 Sentinel 高可用机制
在生产环境中，单台 Redis 实例面临**单点故障**、**无法扩容**等问题。为了解决这类问题，Redis 提供了主从复制和哨兵机制（Sentinel），实现基本的高可用。

---

## 主从复制（Replication）
### 作用
+ 实现读写分离（主写从读）
+ 提供故障转移能力的基础
+ 多机热备，提高数据安全性

### 架构示意
```plain
Client
       |
    +------+       +------+
    | Master | --> | Slave1|
    +------+       +------+
                      |
                   +------+
                   |Slave2|
                   +------+
```

### 启动主从复制
在从库的 redis.conf 中设置：

```bash
replicaof <master-ip> <master-port>
```

或者运行时命令：

```bash
replicaof 127.0.0.1 6379
```

### 同步过程
1. 从库连接主库，发送 `PSYNC` 命令
2. 首次同步：主库执行 BGSAVE 生成 RDB 文件并发送给从库
3. 增量同步：之后通过命令流（replication backlog）持续同步

### 特点
+ 主库写，从库同步，数据最终一致
+ 从库是只读状态
+ 支持链式结构（slave -> slave）

---

## Sentinel（哨兵）机制
### 作用
+ 自动监控 Redis 主从节点状态
+ 主节点故障时，**自动故障转移（failover）**
+ 提供主节点的服务发现功能

### 架构图
```plain
+---------+         +---------+         +---------+
|Sentinel1|         |Sentinel2|         |Sentinel3|
+----+----+         +----+----+         +----+----+
     \                    |                   /
      \                  |                  /
       \                |                 /
        +------------+  |  +------------+
                     |  |  |
                  +--v--v--v--+
                  |  Master   |
                  +--+-----+--+
                     |     |
                  +--v--+ +--v--+
                  |Slave1| |Slave2|
                  +------+ +------+
```

### 核心组件
1. **监控（Monitor）**：定时 PING 主从节点
2. **通知（Notification）**：主节点异常后发起故障报告
3. **投票（Leader Election）**：多个哨兵协商选主
4. **故障转移（Failover）**：重新选主并通知所有从库更新主节点

### 配置示例
```bash
sentinel monitor mymaster 127.0.0.1 6379 2
sentinel down-after-milliseconds mymaster 5000
sentinel failover-timeout mymaster 10000
sentinel parallel-syncs mymaster 1
```

### 特点
+ 最少部署 3 个哨兵节点，确保仲裁可靠性
+ 会自动修改从库指向新主库
+ 与客户端配合使用，实现服务发现（客户端动态连接主节点）

---

## 自问自答
1. Redis 主从同步机制是什么？全量同步和增量同步怎么实现？
2. Redis Sentinel 的作用是什么？如何实现自动故障转移？
3. Redis 主从架构如何避免脑裂？
4. Redis 从库能写入吗？为什么？
5. Redis Sentinel 和 ZooKeeper 的区别？

---

## 实战建议
| 建议 | 理由 |
| --- | --- |
| 使用至少 1 主 2 从 3 哨兵结构 | 实现高可用、读写分离 |
| 设置 `min-slaves-to-write` | 保证主库写操作安全 |
| Sentinel + 客户端主节点发现 | 防止客户端连接老主节点 |
| 定期监控主从延迟 | 避免读到旧数据 |


# Redis 主从架构如何避免脑裂
## 使用 Redis Sentinel（哨兵）
Redis Sentinel 是官方提供的高可用性解决方案，主要用于监控 Redis 实例的状态，进行故障转移，并通知管理员。通过 Redis Sentinel 可以有效避免脑裂问题，具体做法包括：

+ **监控主从节点**：Sentinel 定期检查 Redis 实例的健康状况，一旦主节点不可用，Sentinel 会自动选举一个新的主节点。
+ **故障转移**：当检测到主节点不可用时，Sentinel 会从从节点中选举一个新的主节点，自动进行故障转移，确保服务的持续可用。
+ **通知报警**：在发生故障时，Sentinel 会通过邮件、短信等方式通知管理员，便于及时处理。

这种方式可以确保即使主节点失效，从节点能够迅速接管，减少脑裂的风险。

## 配置 `auto-aof-rewrite` 和 `appendonly`
Redis 在启用 AOF（Append Only File）持久化模式时，每个写操作都会被记录到 AOF 文件中，这样可以在恢复时保持数据一致性。脑裂发生时，如果从节点与主节点的数据不一致，AOF 文件可以在重启时应用，确保数据恢复。

然而，仅依赖 AOF 并不能完全避免脑裂，结合 Redis Sentinel 可以增强整体的高可用性和一致性。

## 配置 `min-slaves-to-write` 和 `min-slaves-max-lag`
为了减少脑裂的可能性，可以在主节点上配置以下参数：

+ `**min-slaves-to-write**`：在进行写操作时，主节点要求至少有 N 个从节点同步确认。这有助于确保主节点的数据不会丢失，并避免主从数据不一致。
+ `**min-slaves-max-lag**`：限制从节点的最大延迟，如果某些从节点的同步延迟过大，主节点将停止接受写操作，避免因为数据延迟而导致的数据不一致。

通过这些配置，确保主节点只有在至少一部分从节点同步成功的情况下才会执行写操作，有助于减少脑裂的发生。

## 使用 Redis Cluster（集群）
Redis 集群是一种分布式部署方式，能够通过分片将数据分布到多个节点上，每个主节点都有一个或多个从节点进行备份。在 Redis 集群中：

+ **主从备份**：每个主节点都有一个或多个从节点作为备份，确保主节点故障时可以进行快速的故障转移。
+ **自动选举**：集群内部会自动进行主节点的选举，避免了因为某个节点不可用而导致的数据不一致。
+ **PAXOS 或 Raft 协议**：集群内部使用一致性协议来确保数据的一致性，避免脑裂问题。

使用 Redis 集群可以通过分布式架构减少单点故障的影响，自动化的故障转移机制有效降低了脑裂发生的几率。

## 合理设计客户端架构
为了避免在 Redis 主从架构中发生脑裂问题，客户端架构需要能够动态适应主从节点的变化。现代 Redis 客户端（如 `redis-py`）通常支持与 Redis Sentinel 或 Redis Cluster 协作，能够自动获取当前的主节点信息，并在发生故障时自动切换连接。

客户端应具备以下功能：

+ **自动发现主节点**：客户端能够自动从 Sentinel 或集群获取主节点信息，确保在节点变化时无缝切换。
+ **支持故障转移**：客户端支持 Sentinel 的故障转移机制，能够在主节点不可用时自动连接到新的主节点。

通过设计智能客户端，可以减少由于节点故障带来的脑裂问题。

## 监控和报警系统
除了配置 Redis Sentinel 和 Redis 集群外，建立全面的监控和报警系统同样重要。通过监控 Redis 实例的健康状态，可以在节点出现异常时及时发现问题，避免脑裂的发生。

常见的监控项包括：

+ 节点的连接状态和响应时间
+ 主从同步的延迟
+ Redis 实例的内存和 CPU 使用情况

结合报警系统，确保在发生故障时能够迅速采取措施进行修复，防止脑裂的发生。

## 总结
通过使用 Redis Sentinel 或 Redis 集群，并合理配置主从同步策略，可以有效避免 Redis 主从架构中的脑裂问题。此外，设计智能客户端架构和建立完善的监控报警机制，也能进一步提升系统的容错能力，确保 Redis 在高可用性和一致性方面的稳定运行。



# Redis Sentinel 和 ZooKeeper 的区别
## 设计目标和功能
**Redis Sentinel**： Redis Sentinel 是专为 Redis 提供高可用性解决方案的工具。它主要负责监控 Redis 实例，检测主节点的状态，并在主节点故障时执行自动故障转移，将从节点提升为新的主节点。它的核心功能包括故障检测、故障转移、通知和监控。Redis Sentinel 适用于 Redis 集群的高可用性管理。

**ZooKeeper**： ZooKeeper 是一个分布式协调服务，旨在帮助不同的分布式应用系统管理配置、命名、同步服务等。它不仅限于 Redis，广泛用于需要高一致性和协调的分布式系统中。ZooKeeper 提供了分布式锁、配置管理、节点监控、领导者选举等多种功能，适用于大规模的分布式应用。ZooKeeper 提供的强一致性协议使得它适用于任何需要分布式协调的应用。

## 总结
Redis Sentinel 和 ZooKeeper 都是高可用性和分布式系统中的重要工具，但它们的应用场景、设计目标和功能有所不同。Redis Sentinel 专为 Redis 提供高可用性解决方案，适用于 Redis 集群的监控和故障转移。而 ZooKeeper 是一个通用的分布式协调服务，适用于广泛的分布式系统，提供强一致性和协调功能，支持更复杂的分布式应用。

